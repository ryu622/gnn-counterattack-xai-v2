{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcJF1XYmFWE+2ZW0L4wrsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryu622/gnn-counterattack-xai-v2/blob/feat%2Fnew-file/GAT_CounterAttack_Prediction_Train_Scientific9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNNã«ç‰©ç†çš„ãªæ¤œé–²ã‚’åŠ ãˆãŸãƒ¢ãƒ‡ãƒ«ï¼ˆGATã‚’æ‹¡å¼µã—ã¦ä½œæˆã€‚ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã®å¯è¦–åŒ–ã€é †åˆ—ç‰¹å¾´é‡è¦åº¦ã€GNNExplainerã¾ã§å®Ÿè£…ï¼‰"
      ],
      "metadata": {
        "id": "uk3cy9-leg2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ã‚·ãƒ¼ãƒ‰å€¤\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    # Pythonè‡ªä½“ã®ä¹±æ•°å›ºå®š\n",
        "    random.seed(seed)\n",
        "    # OSç’°å¢ƒã®ä¹±æ•°å›ºå®š\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # Numpyã®ä¹±æ•°å›ºå®š\n",
        "    np.random.seed(seed)\n",
        "    # PyTorchã®ä¹±æ•°å›ºå®š\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # ãƒãƒ«ãƒGPUã®å ´åˆ\n",
        "    # è¨ˆç®—ã®æ±ºå®šè«–çš„æŒ™å‹•ã‚’å¼·åˆ¶ï¼ˆã“ã‚Œã‚’å…¥ã‚Œã‚‹ã¨å°‘ã—é…ããªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ãŒã€å†ç¾æ€§ã¯å®Œç’§ã«ãªã‚Šã¾ã™ï¼‰\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# å¥½ããªæ•°å­—ï¼ˆ42ãŒä¸€èˆ¬çš„ï¼‰ã§å›ºå®š\n",
        "set_seed(44)"
      ],
      "metadata": {
        "id": "n48oYvKTjBv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. ç’°å¢ƒè¨­å®šã¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ---\n",
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install torch-scatter torch-sparse torch-geometric sklearn tqdm networkx matplotlib\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã«å¿…é ˆï¼‰\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import logging\n",
        "import copy\n",
        "\n",
        "# ãƒ­ã‚¬ãƒ¼è¨­å®š\n",
        "logger = logging.getLogger(__name__)\n",
        "if not logger.handlers:\n",
        "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
        "    logger.addHandler(stdout_handler)\n",
        "\n",
        "print(\"STEP 1 å®Œäº†: ç’°å¢ƒè¨­å®šã¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚\")"
      ],
      "metadata": {
        "id": "oQL105GpjEka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWs4offliq4t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "\n",
        "class PIGNNLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, tau=0.20):\n",
        "        super(PIGNNLayer, self).__init__(aggr='add')\n",
        "        self.tau = tau\n",
        "        self.lin = nn.Linear(in_channels, out_channels)\n",
        "        self.att = nn.Parameter(torch.Tensor(1, out_channels * 2))\n",
        "        nn.init.xavier_uniform_(self.att)\n",
        "        self.last_alpha = None\n",
        "\n",
        "    # forwardã®å¼•æ•°ã‚’ (x, edge_index, pos, prev_pos, pprev_pos) ã®5ã¤ã«ã™ã‚‹\n",
        "    def forward(self, x, edge_index, pos, prev_pos, pprev_pos):\n",
        "        h = self.lin(x)\n",
        "        # å¿…è¦ãªæƒ…å ±ã‚’ã™ã¹ã¦ propagate ã«æ¸¡ã™\n",
        "        return self.propagate(edge_index, x=h, pos=pos, prev_pos=prev_pos, pprev_pos=pprev_pos)\n",
        "\n",
        "    # messageé–¢æ•°ã®å¼•æ•°åã¯ã€propagateã§æ¸¡ã—ãŸåå‰ (x, pos, ...) ã« _i ã‚„ _j ã‚’ã¤ã‘ãŸã‚‚ã®\n",
        "    def message(self, x_i, x_j, pos_j, prev_pos_j, pprev_pos_j, edge_index_i):\n",
        "        # ç‰©ç†äºˆæ¸¬\n",
        "        calc_prev_vel_j = (prev_pos_j - pprev_pos_j) / self.tau\n",
        "        expected_curr_pos_j = prev_pos_j + calc_prev_vel_j * self.tau\n",
        "        residual = torch.norm(pos_j - expected_curr_pos_j, dim=-1, keepdim=True)\n",
        "\n",
        "        # ç‰©ç†ã‚²ãƒ¼ãƒˆ\n",
        "        gate_steepness = 50.0\n",
        "        threshold = 0.05\n",
        "        reliability_gate = torch.sigmoid(gate_steepness * (threshold - residual))\n",
        "\n",
        "        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³\n",
        "        alpha = torch.cat([x_i, x_j], dim=-1)\n",
        "        alpha = (alpha * self.att).sum(dim=-1, keepdim=True)\n",
        "        alpha = F.leaky_relu(alpha) + torch.log(reliability_gate + 1e-9)\n",
        "        alpha = softmax(alpha, edge_index_i)\n",
        "\n",
        "        self.last_alpha = alpha.detach()\n",
        "        return alpha * x_j\n",
        "\n",
        "\n",
        "class PIGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels=7, hidden_channels=64):\n",
        "        super(PIGNNClassifier, self).__init__()\n",
        "        self.conv1 = PIGNNLayer(in_channels, hidden_channels)\n",
        "        self.conv2 = PIGNNLayer(hidden_channels, hidden_channels)\n",
        "        self.lin = nn.Linear(hidden_channels, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        # Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å¿…è¦ãªå±æ€§ã‚’æŠ½å‡º\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        pos, prev_pos, pprev_pos = data.pos, data.prev_pos, data.pprev_pos\n",
        "\n",
        "        x = F.elu(self.conv1(x, edge_index, pos, prev_pos, pprev_pos))\n",
        "        x = F.elu(self.conv2(x, edge_index, pos, prev_pos, pprev_pos))\n",
        "\n",
        "        x_pool = global_mean_pool(x, batch)\n",
        "        return F.log_softmax(self.lin(x_pool), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_pignn_epoch_simple(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    # é‡ã¿ä»˜ãNLLLossã®ã¿ã‚’ä½¿ç”¨ï¼ˆalpha_pã¯ä½¿ã‚ãªã„ï¼‰\n",
        "    weights = torch.tensor([1.0, 3.3], device=device)\n",
        "\n",
        "    for data in loader:\n",
        "        data = preprocess_batch(data, device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(data)\n",
        "        # ç‰©ç†ã‚²ãƒ¼ãƒˆãŒè¨ˆç®—ã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€å˜ç´”ãªåˆ†é¡æå¤±ã§ã€Œç‰©ç†ã€ãŒå­¦ç¿’ã•ã‚Œã‚‹\n",
        "        loss = F.nll_loss(out, data.y.view(-1), weight=weights)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "f6yNqt4bi9ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def balance_dataset_by_undersampling(data_list):\n",
        "    \"\"\"\n",
        "    æˆåŠŸ(y=1)ã¨å¤±æ•—(y=0)ã®ãƒ‡ãƒ¼ã‚¿ã‚’1:1ã®å‰²åˆã«èª¿æ•´ã™ã‚‹é–¢æ•°\n",
        "    \"\"\"\n",
        "    success_data = [d for d in data_list if d.y.item() == 1]\n",
        "    failure_data = [d for d in data_list if d.y.item() == 0]\n",
        "\n",
        "    n_success = len(success_data)\n",
        "    n_failure = len(failure_data)\n",
        "\n",
        "    # å°‘ãªã„æ–¹ã®ã‚¯ãƒ©ã‚¹ã®æ•°ã«åˆã‚ã›ã¦ã€å¤šã„æ–¹ã®ã‚¯ãƒ©ã‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
        "    if n_success < n_failure:\n",
        "        # æˆåŠŸãŒå°‘ãªã„å ´åˆã€å¤±æ•—ã‚’æ¸›ã‚‰ã™\n",
        "        sampled_failure = random.sample(failure_data, n_success)\n",
        "        balanced_list = success_data + sampled_failure\n",
        "    else:\n",
        "        # å¤±æ•—ãŒå°‘ãªã„å ´åˆã€æˆåŠŸã‚’æ¸›ã‚‰ã™\n",
        "        sampled_success = random.sample(success_data, n_failure)\n",
        "        balanced_list = failure_data + sampled_success\n",
        "\n",
        "    random.shuffle(balanced_list)\n",
        "    print(f\"  >> ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å®Œäº†: æˆåŠŸ {min(n_success, n_failure)}ä»¶ / å¤±æ•— {min(n_success, n_failure)}ä»¶\")\n",
        "    return balanced_list"
      ],
      "metadata": {
        "id": "GWBozxPRtfL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. ãƒ‡ãƒã‚¤ã‚¹æº–å‚™\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- ã€é‡è¦ã€‘ç‰©ç†ã‚²ãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã¯ FIXED_ALPHA (æå¤±ã¸ã®åŠ ç®—) ã¯ä¸è¦ã§ã™ ---\n",
        "# ã‚‚ã—ä»¥å‰ã¨ã®æ¯”è¼ƒç”¨ã«æ®‹ã—ãŸã„å ´åˆä»¥å¤–ã¯ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚\n",
        "\n",
        "# 2. ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰\n",
        "v17_load_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/gnn_data_v18_final.pt\"\n",
        "print(f\"CVç”¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {v17_load_path}\")\n",
        "checkpoint = torch.load(v17_load_path, weights_only=False)\n",
        "all_data_list = checkpoint['all_data']\n",
        "\n",
        "# è©¦åˆIDã®å–å¾— (Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå†…ã® match_id ã‚’å‚ç…§)\n",
        "match_ids = sorted(list(set([int(d.match_id.item()) for d in all_data_list])))\n",
        "print(f\"æ¤œå‡ºã•ã‚ŒãŸè©¦åˆID: {match_ids} (è¨ˆ {len(match_ids)} è©¦åˆ)\")\n",
        "\n",
        "# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "EPOCHS_CV = 100\n",
        "LR = 0.0005\n",
        "cv_final_reports = []\n",
        "best_overall_f1 = 0\n",
        "all_cv_history = []\n",
        "\n",
        "print(f\"PIGNN ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ (ç‰©ç†æ•´åˆæ€§ã‚²ãƒ¼ãƒˆãƒ»æ§‹é€ åˆ¶ç´„ãƒ¢ãƒ¼ãƒ‰)\\n\")\n",
        "\n",
        "for test_match in match_ids:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\" Round: Match {test_match} ã‚’ãƒ†ã‚¹ãƒˆã«ä½¿ç”¨\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # 1. ãƒ‡ãƒ¼ã‚¿ã®åˆ‡ã‚Šåˆ†ã‘\n",
        "    test_indices = [d for d in all_data_list if int(d.match_id.item()) == test_match]\n",
        "    train_candidates = [d for d in all_data_list if int(d.match_id.item()) != test_match]\n",
        "\n",
        "    # 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã¿1:1ã‚¢ãƒ³ãƒ€ãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (å¤–éƒ¨é–¢æ•°ã‚’å‘¼ã³å‡ºã—)\n",
        "    cv_train_set = balance_dataset_by_undersampling(train_candidates)\n",
        "\n",
        "    cv_train_loader = DataLoader(cv_train_set, batch_size=32, shuffle=True)\n",
        "    cv_test_loader = DataLoader(test_indices, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 3. ãƒ¢ãƒ‡ãƒ«ãƒ»æœ€é©åŒ–æ‰‹æ³•ã®åˆæœŸåŒ– (in_channels=7 ã«æ³¨æ„)\n",
        "    cv_model = PIGNNClassifier(in_channels=7, hidden_channels=64).to(device)\n",
        "    cv_optimizer = torch.optim.Adam(cv_model.parameters(), lr=LR)\n",
        "\n",
        "    # ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾ç­–ã®é‡ã¿ (Failure:Success = 1:3.3)\n",
        "    weights = torch.tensor([1.0, 1.0]).to(device)\n",
        "    criterion = torch.nn.NLLLoss(weight=weights)\n",
        "\n",
        "    round_history = {'total_loss': []}\n",
        "\n",
        "    # 4. å­¦ç¿’ãƒ«ãƒ¼ãƒ—\n",
        "    for epoch in range(1, EPOCHS_CV + 1):\n",
        "        cv_model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in cv_train_loader:\n",
        "            batch = batch.to(device)\n",
        "            cv_optimizer.zero_grad()\n",
        "\n",
        "            # æ¨è«– (ç‰©ç†ã‚²ãƒ¼ãƒˆã¯ãƒ¢ãƒ‡ãƒ«å†…éƒ¨ã§è‡ªå‹•ä½œå‹•)\n",
        "            out = cv_model(batch)\n",
        "\n",
        "            # ç´”ç²‹ãªåˆ†é¡æå¤±ã®ã¿\n",
        "            loss = criterion(out, batch.y.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            cv_optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(cv_train_loader)\n",
        "        round_history['total_loss'].append(avg_loss)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"  Epoch {epoch:02d} | Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    all_cv_history.append(round_history)\n",
        "\n",
        "    # 5. è©•ä¾¡\n",
        "    cv_model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for data in cv_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = cv_model(data)\n",
        "            y_true.extend(data.y.view(-1).cpu().numpy())\n",
        "            y_pred.extend(out.argmax(dim=1).cpu().numpy())\n",
        "\n",
        "    # ã‚¹ã‚³ã‚¢é›†è¨ˆ\n",
        "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "    current_f1 = report['Success']['f1-score'] if 'Success' in report else report['1']['f1-score']\n",
        "\n",
        "    cv_final_reports.append({\n",
        "        'match': test_match,\n",
        "        'recall': report['1']['recall'] if '1' in report else report['Success']['recall'],\n",
        "        'precision': report['1']['precision'] if '1' in report else report['Success']['precision'],\n",
        "        'f1': current_f1\n",
        "    })\n",
        "\n",
        "    # ä¿å­˜\n",
        "    base_model_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Models/PIGNN_v17_Gate\"\n",
        "    os.makedirs(base_model_dir, exist_ok=True)\n",
        "    torch.save(cv_model.state_dict(), os.path.join(base_model_dir, f'pignn_match_{test_match}.pth'))\n",
        "\n",
        "    if current_f1 > best_overall_f1:\n",
        "        best_overall_f1 = current_f1\n",
        "        torch.save(cv_model.state_dict(), os.path.join(base_model_dir, 'best_overall_pignn.pth'))\n",
        "        print(f\" New Best Model! F1={best_overall_f1:.4f}\")\n",
        "\n",
        "# 6. æœ€çµ‚é›†è¨ˆ\n",
        "print(f\"\\n\\n{'#'*60}\\n  PIGNN (Gate Mode) CV æœ€çµ‚å¹³å‡çµæœ\\n{'#'*60}\")\n",
        "print(f\"Avg Success Recall:    {np.mean([r['recall'] for r in cv_final_reports]):.4f}\")\n",
        "print(f\"Avg Success Precision: {np.mean([r['precision'] for r in cv_final_reports]):.4f}\")\n",
        "print(f\"Avg Success F1-score:  {np.mean([r['f1'] for r in cv_final_reports]):.4f}\")\n",
        "\n",
        "# 7. å­¦ç¿’æ›²ç·šã®æç”»\n",
        "avg_total_loss = np.mean([h['total_loss'] for h in all_cv_history], axis=0)\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, EPOCHS_CV + 1), avg_total_loss, label='Avg Training Loss')\n",
        "plt.title('PIGNN Learning Curve (Physics Gate Mode)')\n",
        "plt.xlabel('Epochs'); plt.ylabel('Loss'); plt.grid(True); plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lsh9d5Z6i94E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def visualize_attention(model, data, sample_idx=0):\n",
        "    \"\"\"\n",
        "    ç‰¹å®šã®ã‚·ãƒ¼ãƒ³ã«ãŠã‘ã‚‹ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã¨ç‰©ç†ã‚²ãƒ¼ãƒˆã®å½±éŸ¿ã‚’å¯è¦–åŒ–ã™ã‚‹\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "    data = data.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # æ¨è«–å®Ÿè¡Œï¼ˆã“ã®æ™‚ã€å†…éƒ¨ã§ self.conv1.last_alpha ã«ä¿‚æ•°ãŒä¿å­˜ã•ã‚Œã‚‹ï¼‰\n",
        "        out = model(data)\n",
        "        probs = torch.exp(out) # log_softmaxã‚’ç¢ºç‡ã«æˆ»ã™\n",
        "\n",
        "        # æœ€çµ‚å±¤ã¾ãŸã¯ç¬¬1å±¤ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã‚’å–å¾— [num_edges, 1]\n",
        "        alpha = model.conv1.last_alpha\n",
        "        edge_index = data.edge_index\n",
        "\n",
        "    # åº§æ¨™ãƒ‡ãƒ¼ã‚¿ã®å–å¾—\n",
        "    pos = data.pos.cpu().numpy()\n",
        "    x = pos[:, 0] * 52.5  # æ­£è¦åŒ–ã‚’ãƒ¡ãƒ¼ãƒˆãƒ«ã«æˆ»ã™\n",
        "    y = pos[:, 1] * 34.0\n",
        "    node_features = data.x.cpu().numpy()\n",
        "\n",
        "    # ãƒ”ãƒƒãƒã®æç”»\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.set_facecolor('#77dd77') # ç·‘è‰²ã®ãƒ”ãƒƒãƒ\n",
        "\n",
        "    # ã‚µãƒƒã‚«ãƒ¼ãƒ”ãƒƒãƒã®æ çµ„ã¿\n",
        "    plt.plot([-52.5, 52.5, 52.5, -52.5, -52.5], [-34, -34, 34, 34, -34], color=\"white\", lw=2)\n",
        "    plt.plot([0, 0], [-34, 34], color=\"white\", lw=2) # ã‚»ãƒ³ã‚¿ãƒ¼ãƒ©ã‚¤ãƒ³\n",
        "\n",
        "    # ã‚¨ãƒƒã‚¸ï¼ˆã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ï¼‰ã®æç”»\n",
        "    # ã™ã¹ã¦æç”»ã™ã‚‹ã¨è¦‹ã¥ã‚‰ã„ãŸã‚ã€ä¸Šä½20%ã¾ãŸã¯é–¾å€¤ä»¥ä¸Šã‚’æç”»\n",
        "    max_alpha = alpha.max().item()\n",
        "    for k in range(edge_index.shape[1]):\n",
        "        src, dst = edge_index[0, k], edge_index[1, k]\n",
        "        weight = alpha[k].item()\n",
        "\n",
        "        # ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®å¼·ã•ã‚’ç·šã®å¤ªã•ã¨é€æ˜åº¦ã§è¡¨ç¾\n",
        "        if weight > max_alpha * 0.1: # ä¸Šä½ã®ä¿‚æ•°ã®ã¿è¡¨ç¤º\n",
        "            plt.plot([x[src], x[dst]], [y[src], y[dst]],\n",
        "                     color='yellow', alpha=min(1.0, weight*5),\n",
        "                     lw=weight*10, zorder=1)\n",
        "\n",
        "    # ãƒãƒ¼ãƒ‰ï¼ˆé¸æ‰‹ãƒ»ãƒœãƒ¼ãƒ«ï¼‰ã®æç”»\n",
        "    for i in range(len(x)):\n",
        "        team_val = node_features[i, 6]\n",
        "        if team_val == 2.0: # ãƒœãƒ¼ãƒ«\n",
        "            color, marker, size = 'white', 'o', 100\n",
        "        elif team_val == 0.0: # Home\n",
        "            color, marker, size = 'blue', 's', 200\n",
        "        else: # Away\n",
        "            color, marker, size = 'red', 's', 200\n",
        "\n",
        "        ax.scatter(x[i], y[i], c=color, marker=marker, s=size, edgecolors='black', zorder=2)\n",
        "\n",
        "    plt.title(f\"Attention Weights Visualization\\nSuccess Prob: {probs[0,1]:.4f} | Label: {data.y.item()}\")\n",
        "    plt.xlim(-60, 60)\n",
        "    plt.ylim(-40, 40)\n",
        "    plt.show()\n",
        "\n",
        "# --- å®Ÿè¡Œä¾‹ ---\n",
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®ã‚·ãƒ¼ãƒ³ã‚’è¡¨ç¤º\n",
        "test_data_sample = all_data_list[0] # ã¾ãŸã¯ä»»æ„ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
        "visualize_attention(cv_model, test_data_sample)"
      ],
      "metadata": {
        "id": "_uJ1c93JyDfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# ==========================================\n",
        "# 1. å¯è¦–åŒ– & æ•°å€¤æŠ½å‡ºãƒ¡ã‚¤ãƒ³é–¢æ•°\n",
        "# ==========================================\n",
        "def visualize_pignn_tactical_analysis(model, data_item, device, title=\"PIGNN Tactical Analysis\"):\n",
        "    model.eval()\n",
        "    data_item = data_item.to(device)\n",
        "\n",
        "    # --- æ¨è«–ã¨ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ»ã‚²ãƒ¼ãƒˆæƒ…å ±ã®æŠ½å‡º ---\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã®forwardã‚’ä¿®æ­£ã—ã¦ attentionã‚’è¿”ã›ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã‚‹å‰æ\n",
        "    with torch.no_grad():\n",
        "        out = model(data_item)\n",
        "        # æœ€å¾Œã«è¨ˆç®—ã•ã‚ŒãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã‚’å–å¾— (PIGNNLayerã§ä¿æŒã—ã¦ã„ã‚‹ã‚‚ã®)\n",
        "        # 2å±¤æ§‹é€ ã®å ´åˆã¯ conv1 ã¾ãŸã¯ conv2 ã® alpha ã‚’å–å¾—\n",
        "        att_weights = model.conv1.last_alpha\n",
        "        edge_index = data_item.edge_index\n",
        "\n",
        "        prob = torch.exp(out)[0, 1].item() # log_softmax ãªã®ã§ exp ã‚’å–ã‚‹\n",
        "        pred = out.argmax(dim=1).item()\n",
        "        label = data_item.y.item()\n",
        "\n",
        "    # --- åº§æ¨™ã¨é€Ÿåº¦ã®å¾©å…ƒ ---\n",
        "    pos = data_item.pos.cpu().numpy()\n",
        "    # é€Ÿåº¦ã¯ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã® index 2, 3 ã«å…¥ã£ã¦ã„ã‚‹ (px, py, vx, vy, ...)\n",
        "    vel = data_item.x[:, 2:4].cpu().numpy()\n",
        "\n",
        "    pos_plot = np.zeros_like(pos)\n",
        "    pos_plot[:, 0] = pos[:, 0] * 52.5  # ãƒ¡ãƒ¼ãƒˆãƒ«æ›ç®—\n",
        "    pos_plot[:, 1] = pos[:, 1] * 34.0\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "    # --- ã‚µãƒƒã‚«ãƒ¼å ´ã®æç”» ---\n",
        "    ax.set_facecolor('#2e7d32')\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=True, color='#388e3c', zorder=0))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=False, color='white', lw=3, zorder=1))\n",
        "    ax.plot([0, 0], [-34, 34], color='white', lw=3, zorder=1)\n",
        "    ax.add_patch(patches.Circle((0, 0), 9.15, edgecolor=\"white\", facecolor=\"none\", lw=3, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((52.5-16.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "\n",
        "    # --- ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã®æç”» & æ•°å€¤å‡ºåŠ› ---\n",
        "    att_weights = att_weights.cpu().numpy().flatten()\n",
        "    edge_index = edge_index.cpu().numpy()\n",
        "    team_ids = data_item.x[:, 6].cpu().numpy() # 0:Home, 1:Away, 2:Ball\n",
        "\n",
        "    if len(att_weights) > 0:\n",
        "        # ä¸Šä½5%ã‚’è¡¨ç¤ºï¼ˆDFLãƒ‡ãƒ¼ã‚¿ã¯ã‚¨ãƒƒã‚¸æ•°ãŒå¤šã„ãŸã‚ï¼‰\n",
        "        threshold = np.percentile(att_weights, 95)\n",
        "        max_att = att_weights.max()\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\" {title} - TOP ATTENTION DETAILS\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"{'Source':<8} | {'Dest':<8} | {'Weight':<10} | {'Team Relation'}\")\n",
        "        print(f\"{'-'*50}\")\n",
        "\n",
        "        for i in range(edge_index.shape[1]):\n",
        "            if att_weights[i] > threshold:\n",
        "                src, dst = edge_index[0, i], edge_index[1, i]\n",
        "                weight = att_weights[i]\n",
        "\n",
        "                # ãƒãƒ¼ãƒ é–¢ä¿‚ã®è¨€èªåŒ–\n",
        "                rel = \"Teammate\" if team_ids[src] == team_ids[dst] else \"Opponent\"\n",
        "                if team_ids[src] == 2.0: rel = \"Ball -> Player\"\n",
        "\n",
        "                print(f\"Node {src:2d} -> Node {dst:2d} | {weight:.4f}     | {rel}\")\n",
        "\n",
        "                # æç”»ï¼ˆé»„è‰²ã„ç·šï¼‰\n",
        "                alpha_val = (weight - threshold) / (max_att - threshold + 1e-9)\n",
        "                ax.plot([pos_plot[src, 0], pos_plot[dst, 0]],\n",
        "                        [pos_plot[src, 1], pos_plot[dst, 1]],\n",
        "                        color='#FFFF00', alpha=min(1.0, alpha_val * 1.2),\n",
        "                        lw=1.0 + alpha_val*5, zorder=2)\n",
        "\n",
        "    # --- é¸æ‰‹ã¨é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«ã®æç”» ---\n",
        "    vel_scale = 10.0\n",
        "    for i in range(len(pos_plot)):\n",
        "        if team_ids[i] == 2.0: # ãƒœãƒ¼ãƒ«\n",
        "            color, marker, size, z = 'gold', '*', 600, 15\n",
        "        elif team_ids[i] == 0.0: # ãƒ›ãƒ¼ãƒ ï¼ˆæ”»æ’ƒå´ã¨æƒ³å®šï¼‰\n",
        "            color, marker, size, z = '#0288d1', 'o', 300, 10\n",
        "        else: # ã‚¢ã‚¦ã‚§ã‚¤ï¼ˆå®ˆå‚™å´ã¨æƒ³å®šï¼‰\n",
        "            color, marker, size, z = '#d32f2f', 'o', 300, 10\n",
        "\n",
        "        # é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«\n",
        "        if team_ids[i] != 2.0:\n",
        "            ax.quiver(pos_plot[i, 0], pos_plot[i, 1],\n",
        "                      vel[i, 0], vel[i, 1],\n",
        "                      color='white', alpha=0.7, angles='xy', scale_units='xy',\n",
        "                      scale=1/vel_scale, width=0.004, zorder=20)\n",
        "\n",
        "        # é¸æ‰‹ãƒãƒ¼ãƒ‰\n",
        "        ax.scatter(pos_plot[i, 0], pos_plot[i, 1], c=color, marker=marker, s=size,\n",
        "                   edgecolors='white', linewidth=1.5, zorder=15)\n",
        "\n",
        "    # --- ãƒ†ã‚­ã‚¹ãƒˆè¨­å®š ---\n",
        "    res_text = \"SUCCESS\" if pred == 1 else \"FAILURE\"\n",
        "    match_status = \"CORRECT\" if label == pred else \"INCORRECT\"\n",
        "    ax.set_title(f\"{title}\\nActual: {'SUCCESS' if label==1 else 'FAILURE'} | Predicted: {res_text} ({prob:.1%})\\nResult: {match_status}\",\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "    ax.set_xlim(-60, 60); ax.set_ylim(-40, 40)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# 2. è‡ªå‹•æŠ½å‡ºãƒ»æ¯”è¼ƒå®Ÿè¡Œé–¢æ•°\n",
        "# ==========================================\n",
        "def run_tactical_comparison(model, data_list, device):\n",
        "    success_case, failure_case = None, None\n",
        "    model.eval()\n",
        "\n",
        "    # æ­£è§£ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã®ä¸­ã‹ã‚‰ã€æˆåŠŸã‚·ãƒ¼ãƒ³ã¨å¤±æ•—ã‚·ãƒ¼ãƒ³ã‚’1ã¤ãšã¤æ¢ã™\n",
        "    for data in data_list:\n",
        "        with torch.no_grad():\n",
        "            d_gpu = data.to(device)\n",
        "            out = model(d_gpu)\n",
        "            pred = out.argmax(dim=1).item()\n",
        "            label = d_gpu.y.item()\n",
        "\n",
        "            if pred == label:\n",
        "                if label == 1 and success_case is None: success_case = data\n",
        "                elif label == 0 and failure_case is None: failure_case = data\n",
        "        if success_case is not None and failure_case is not None: break\n",
        "\n",
        "    if success_case:\n",
        "        visualize_pignn_tactical_analysis(model, success_case, device, title=\"PIGNN Analysis: True Positive (Success)\")\n",
        "    if failure_case:\n",
        "        visualize_pignn_tactical_analysis(model, failure_case, device, title=\"PIGNN Analysis: True Negative (Failure)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. å®Ÿè¡Œ\n",
        "# ==========================================\n",
        "# æ³¨æ„: ã™ã§ã« PIGNNClassifier ã¯å®šç¾©æ¸ˆã¿ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "# ä»Šå›ã®ç‰©ç†ã‚²ãƒ¼ãƒˆç‰ˆ (in_channels=7) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "model_viz = PIGNNClassifier(in_channels=7, hidden_channels=64).to(device)\n",
        "\n",
        "# CVã§ä¿å­˜ã—ãŸãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "best_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Models/PIGNN_v17_Gate/best_overall_pignn.pth\"\n",
        "if os.path.exists(best_path):\n",
        "    model_viz.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    print(\"å¯è¦–åŒ–ç”¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸã€‚\")\n",
        "    run_tactical_comparison(model_viz, all_data_list, device)\n",
        "else:\n",
        "    print(f\" ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {best_path}\")"
      ],
      "metadata": {
        "id": "WT_dgnQ_yZIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def analyze_node_attention_bias(model, data_list, device, top_n=5):\n",
        "    model.eval()\n",
        "    node_att_score = defaultdict(float)\n",
        "    node_count = defaultdict(int)\n",
        "\n",
        "    print(\" å…¨ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ãƒ‰åˆ¥ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é›†è¨ˆã‚’é–‹å§‹...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_list:\n",
        "            data = data.to(device)\n",
        "            _ = model(data)\n",
        "            # æœ€å¾Œã«è¨ˆç®—ã•ã‚ŒãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³(Layer1)ã‚’å–å¾—\n",
        "            att = model.conv1.last_alpha.cpu().numpy().flatten()\n",
        "            edge_index = data.edge_index.cpu().numpy()\n",
        "\n",
        "            for i in range(len(att)):\n",
        "                dst = edge_index[1, i] # å—ã‘å–ã‚Šå´ãƒãƒ¼ãƒ‰\n",
        "                node_att_score[dst] += att[i]\n",
        "                node_count[dst] += 1\n",
        "\n",
        "    # å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ç²å¾—ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n",
        "    rank = []\n",
        "    for node_idx in node_att_score:\n",
        "        avg_score = node_att_score[node_idx] / node_count[node_idx]\n",
        "        rank.append((node_idx, avg_score))\n",
        "\n",
        "    rank = sorted(rank, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    print(f\"\\n ãƒãƒ¼ãƒ‰åˆ¥ å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ç²å¾—ãƒ©ãƒ³ã‚­ãƒ³ã‚° (TOP {top_n})\")\n",
        "    print(\"-\" * 45)\n",
        "    for i, (idx, score) in enumerate(rank[:top_n]):\n",
        "        role = \"GK? (Static Bias)\" if i == 0 else \"Active Player\"\n",
        "        print(f\"Rank {i+1}: Node {idx:2d} | Avg Attention: {score:.4f} | {role}\")\n",
        "\n",
        "    return [r[0] for r in rank[:2]] # ä¸Šä½2åã‚’GKå€™è£œã¨ã—ã¦è¿”ã™\n",
        "\n",
        "def get_fp_only_stats(model, data_list, device, gk_indices):\n",
        "    model.eval()\n",
        "    all_fp_att = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_list:\n",
        "            data = data.to(device)\n",
        "            _ = model(data)\n",
        "            att = model.conv1.last_alpha.cpu().numpy().flatten()\n",
        "            edge_index = data.edge_index.cpu().numpy()\n",
        "\n",
        "            # GKã‚’é™¤å¤–ã—ãŸã‚¨ãƒƒã‚¸ã®ä¿‚æ•°ã®ã¿ã‚’æŠ½å‡º\n",
        "            mask = ~np.isin(edge_index[0], gk_indices) & ~np.isin(edge_index[1], gk_indices)\n",
        "            fp_att = att[mask]\n",
        "            all_fp_att.extend(fp_att.tolist())\n",
        "\n",
        "    print(f\"\\n FP(ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼)é–“ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³çµ±è¨ˆ (GK: {gk_indices} é™¤å¤–)\")\n",
        "    print(\"-\" * 45)\n",
        "    print(f\"FPã‚¨ãƒƒã‚¸ç·æ•°: {len(all_fp_att)}\")\n",
        "    print(f\"å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: {np.mean(all_fp_att):.4f}\")\n",
        "    print(f\"æœ€å¤§ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³: {np.max(all_fp_att):.4f}\")\n",
        "    print(f\"æ¨™æº–åå·®:       {np.std(all_fp_att):.4f}\")\n",
        "\n",
        "# ==========================================\n",
        "# å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³\n",
        "# ==========================================\n",
        "# 1. ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’é›†ã‚ã™ãã¦ã„ã‚‹ãƒãƒ¼ãƒ‰ï¼ˆGKå€™è£œï¼‰ã‚’ç‰¹å®š\n",
        "gk_candidates = analyze_node_attention_bias(model_viz, all_data_list, device)\n",
        "\n",
        "# 2. ç‰¹å®šã•ã‚ŒãŸGKå€™è£œã‚’é™¤å¤–ã—ã¦ã€FPã®ã¿ã®ç´”ç²‹ãªçµ±è¨ˆã‚’å‡ºã™\n",
        "get_fp_only_stats(model_viz, all_data_list, device, gk_candidates)"
      ],
      "metadata": {
        "id": "bFB9-TrXzTb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "# ==========================================\n",
        "# 0. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (GKç‰¹å®š)\n",
        "# ==========================================\n",
        "def identify_gk_nodes(model, data_list, device, top_n_candidates=2):\n",
        "    \"\"\"\n",
        "    å…¨ãƒ‡ãƒ¼ã‚¿ã‚’é€šã˜ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ç²å¾—é‡ãŒå¤šã„ãƒãƒ¼ãƒ‰ã‚’ç‰¹å®šã—ã€GKå€™è£œã¨ã—ã¦è¿”å´\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    node_att_score_sum = defaultdict(float)\n",
        "    node_att_count = defaultdict(int)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_list:\n",
        "            data_gpu = data.to(device)\n",
        "            _ = model(data_gpu)\n",
        "            att = model.conv1.last_alpha.cpu().numpy().flatten()\n",
        "            edge_index = data_gpu.edge_index.cpu().numpy()\n",
        "\n",
        "            for i in range(len(att)):\n",
        "                dst = edge_index[1, i] # å—ã‘å–ã‚Šå´ãƒãƒ¼ãƒ‰\n",
        "                node_att_score_sum[dst] += att[i]\n",
        "                node_att_count[dst] += 1\n",
        "\n",
        "    # å¹³å‡ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n",
        "    avg_att_rank = []\n",
        "    for node_idx in node_att_score_sum:\n",
        "        if node_att_count[node_idx] > 0:\n",
        "            avg_att_rank.append((node_idx, node_att_score_sum[node_idx] / node_att_count[node_idx]))\n",
        "\n",
        "    avg_att_rank = sorted(avg_att_rank, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # ä¸Šä½Nåã‚’GKå€™è£œã¨ã—ã¦è¿”ã™ (é€šå¸¸0ç•ªã¨11ç•ªãŒå¤šã„)\n",
        "    gk_candidates = [r[0] for r in avg_att_rank[:top_n_candidates]]\n",
        "    print(f\" identified GK candidates based on avg attention: {gk_candidates}\")\n",
        "    return gk_candidates\n",
        "\n",
        "# ==========================================\n",
        "# 1. å¯è¦–åŒ– & æ•°å€¤æŠ½å‡ºãƒ¡ã‚¤ãƒ³é–¢æ•° (GKè€ƒæ…®ç‰ˆ)\n",
        "# ==========================================\n",
        "def visualize_pignn_tactical_analysis_gk_filtered(model, data_item, device, gk_indices, title=\"PIGNN Tactical Analysis (FP-only)\"):\n",
        "    model.eval()\n",
        "    data_item = data_item.to(device)\n",
        "\n",
        "    # --- æ¨è«–ã¨ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ»ã‚²ãƒ¼ãƒˆæƒ…å ±ã®æŠ½å‡º ---\n",
        "    with torch.no_grad():\n",
        "        out = model(data_item)\n",
        "        att_weights = model.conv1.last_alpha\n",
        "        edge_index = data_item.edge_index\n",
        "\n",
        "        prob = torch.exp(out)[0, 1].item()\n",
        "        pred = out.argmax(dim=1).item()\n",
        "        label = data_item.y.item()\n",
        "\n",
        "    # --- åº§æ¨™ã¨é€Ÿåº¦ã®å¾©å…ƒ ---\n",
        "    pos = data_item.pos.cpu().numpy()\n",
        "    vel = data_item.x[:, 2:4].cpu().numpy() # xã®ç‰¹å¾´é‡ã‹ã‚‰vx, vyã‚’å–å¾—\n",
        "\n",
        "    pos_plot = np.zeros_like(pos)\n",
        "    pos_plot[:, 0] = pos[:, 0] * 52.5  # ãƒ¡ãƒ¼ãƒˆãƒ«æ›ç®—\n",
        "    pos_plot[:, 1] = pos[:, 1] * 34.0\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "    # --- ã‚µãƒƒã‚«ãƒ¼å ´ã®æç”» ---\n",
        "    ax.set_facecolor('#2e7d32')\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=True, color='#388e3c', zorder=0))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=False, color='white', lw=3, zorder=1))\n",
        "    ax.plot([0, 0], [-34, 34], color='white', lw=3, zorder=1)\n",
        "    ax.add_patch(patches.Circle((0, 0), 9.15, edgecolor=\"white\", facecolor=\"none\", lw=3, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((52.5-16.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "\n",
        "    # --- ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã®æç”» & æ•°å€¤å‡ºåŠ› (GKé–¢é€£ã‚¨ãƒƒã‚¸ã¯éè¡¨ç¤º) ---\n",
        "    att_weights = att_weights.cpu().numpy().flatten()\n",
        "    edge_index = edge_index.cpu().numpy()\n",
        "    team_ids = data_item.x[:, 6].cpu().numpy() # 0:Home, 1:Away, 2:Ball\n",
        "\n",
        "    fp_att_values = [] # GKã‚’é™¤å¤–ã—ãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³å€¤ã®ãƒªã‚¹ãƒˆ\n",
        "\n",
        "    if len(att_weights) > 0:\n",
        "        # ä¸Šä½5%ã‚’è¡¨ç¤º\n",
        "        # GKã‚’é™¤å¤–ã—ãŸã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§é–¾å€¤ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã€ä¸€æ™‚çš„ã«FPã®ã¿ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
        "        temp_fp_att = []\n",
        "        for i in range(edge_index.shape[1]):\n",
        "            src, dst = edge_index[0, i], edge_index[1, i]\n",
        "            if src not in gk_indices and dst not in gk_indices:\n",
        "                temp_fp_att.append(att_weights[i])\n",
        "\n",
        "        threshold = np.percentile(temp_fp_att, 95) if temp_fp_att else 0.0\n",
        "        max_att = np.max(temp_fp_att) if temp_fp_att else 1.0\n",
        "\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\" {title} - TOP ATTENTION DETAILS (Excluding GK)\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"{'Source':<8} | {'Dest':<8} | {'Weight':<10} | {'Team Relation'}\")\n",
        "        print(f\"{'-'*50}\")\n",
        "\n",
        "        for i in range(edge_index.shape[1]):\n",
        "            src, dst = edge_index[0, i], edge_index[1, i]\n",
        "            weight = att_weights[i]\n",
        "\n",
        "            # GKé–¢é€£ã®ã‚¨ãƒƒã‚¸ã¯æç”»ãƒ»çµ±è¨ˆã‹ã‚‰é™¤å¤–\n",
        "            if src in gk_indices or dst in gk_indices:\n",
        "                continue\n",
        "\n",
        "            fp_att_values.append(weight) # FPã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒªã‚¹ãƒˆã«è¿½åŠ \n",
        "\n",
        "            if weight > threshold: # ä¸Šä½ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã®ã¿è¡¨ç¤º\n",
        "                # ãƒãƒ¼ãƒ é–¢ä¿‚ã®è¨€èªåŒ–\n",
        "                rel = \"Teammate\" if team_ids[src] == team_ids[dst] else \"Opponent\"\n",
        "                if team_ids[src] == 2.0: rel = \"Ball -> Player\"\n",
        "\n",
        "                print(f\"Node {src:2d} -> Node {dst:2d} | {weight:.4f}     | {rel}\")\n",
        "\n",
        "                # æç”»ï¼ˆé»„è‰²ã„ç·šï¼‰\n",
        "                alpha_val = (weight - threshold) / (max_att - threshold + 1e-9)\n",
        "                ax.plot([pos_plot[src, 0], pos_plot[dst, 0]],\n",
        "                        [pos_plot[src, 1], pos_plot[dst, 1]],\n",
        "                        color='#FFFF00', alpha=min(1.0, alpha_val * 1.2),\n",
        "                        lw=1.0 + alpha_val*5, zorder=2)\n",
        "\n",
        "    # FPã®ã¿ã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³çµ±è¨ˆå‡ºåŠ›\n",
        "    if fp_att_values:\n",
        "        print(f\"\\n FP-only Attention Statistics\")\n",
        "        print(f\"  Count: {len(fp_att_values)}\")\n",
        "        print(f\"  Mean: {np.mean(fp_att_values):.4f}\")\n",
        "        print(f\"  Max: {np.max(fp_att_values):.4f}\")\n",
        "        print(f\"  Std Dev: {np.std(fp_att_values):.4f}\")\n",
        "    else:\n",
        "        print(\"\\nNo FP-only attention edges found for statistics.\")\n",
        "\n",
        "    # --- é¸æ‰‹ã¨é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«ã®æç”» ---\n",
        "    vel_scale = 10.0\n",
        "    for i in range(len(pos_plot)):\n",
        "        if i in gk_indices: # ç‰¹å®šã•ã‚ŒãŸGKã¯ã‚°ãƒ¬ãƒ¼ã‚¢ã‚¦ãƒˆ\n",
        "            color, marker, size, z = 'gray', 'o', 300, 10\n",
        "            edge_color = 'darkgray'\n",
        "            alpha_node = 0.4\n",
        "        elif team_ids[i] == 2.0: # ãƒœãƒ¼ãƒ«\n",
        "            color, marker, size, z = 'gold', '*', 600, 15\n",
        "            edge_color = 'white'\n",
        "            alpha_node = 1.0\n",
        "        elif team_ids[i] == 0.0: # ãƒ›ãƒ¼ãƒ ï¼ˆæ”»æ’ƒå´ã¨æƒ³å®šï¼‰\n",
        "            color, marker, size, z = '#0288d1', 'o', 300, 10\n",
        "            edge_color = 'white'\n",
        "            alpha_node = 1.0\n",
        "        else: # ã‚¢ã‚¦ã‚§ã‚¤ï¼ˆå®ˆå‚™å´ã¨æƒ³å®šï¼‰\n",
        "            color, marker, size, z = '#d32f2f', 'o', 300, 10\n",
        "            edge_color = 'white'\n",
        "            alpha_node = 1.0\n",
        "\n",
        "        # é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ« (GKä»¥å¤–ã®FPã®ã¿æç”»)\n",
        "        if i not in gk_indices and team_ids[i] != 2.0:\n",
        "            ax.quiver(pos_plot[i, 0], pos_plot[i, 1],\n",
        "                      vel[i, 0], vel[i, 1],\n",
        "                      color='white', alpha=alpha_node * 0.7, angles='xy', scale_units='xy',\n",
        "                      scale=1/vel_scale, width=0.004, zorder=20)\n",
        "\n",
        "        # é¸æ‰‹ãƒãƒ¼ãƒ‰\n",
        "        ax.scatter(pos_plot[i, 0], pos_plot[i, 1], c=color, marker=marker, s=size,\n",
        "                   edgecolors=edge_color, linewidth=1.5, zorder=15, alpha=alpha_node)\n",
        "\n",
        "    # --- ã‚¿ã‚¤ãƒˆãƒ«ã¨è¡¨ç¤ºè¨­å®š ---\n",
        "    res_text = \"SUCCESS\" if pred == 1 else \"FAILURE\"\n",
        "    match_status = \"CORRECT\" if label == pred else \"INCORRECT\"\n",
        "    ax.set_title(f\"{title}\\nActual: {'SUCCESS' if label==1 else 'FAILURE'} | Predicted: {res_text} ({prob:.1%})\\nResult: {match_status}\",\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "    ax.set_xlim(-60, 60); ax.set_ylim(-40, 40)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# 2. è‡ªå‹•æŠ½å‡ºãƒ»æ¯”è¼ƒå®Ÿè¡Œé–¢æ•° (GKè€ƒæ…®ç‰ˆ)\n",
        "# ==========================================\n",
        "def run_tactical_comparison_gk_filtered(model, data_list, device, gk_indices):\n",
        "    success_case, failure_case = None, None\n",
        "    model.eval()\n",
        "\n",
        "    # æ­£è§£ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã®ä¸­ã‹ã‚‰ã€æˆåŠŸã‚·ãƒ¼ãƒ³ã¨å¤±æ•—ã‚·ãƒ¼ãƒ³ã‚’1ã¤ãšã¤æ¢ã™\n",
        "    for data in data_list:\n",
        "        with torch.no_grad():\n",
        "            d_gpu = data.to(device)\n",
        "            out = model(d_gpu)\n",
        "            pred = out.argmax(dim=1).item()\n",
        "            label = d_gpu.y.item()\n",
        "\n",
        "            if pred == label:\n",
        "                if label == 1 and success_case is None: success_case = data\n",
        "                elif label == 0 and failure_case is None: failure_case = data\n",
        "        if success_case is not None and failure_case is not None: break\n",
        "\n",
        "    if success_case:\n",
        "        visualize_pignn_tactical_analysis_gk_filtered(model, success_case, device, gk_indices, title=\"PIGNN Analysis: True Positive (FP-only)\")\n",
        "    if failure_case:\n",
        "        visualize_pignn_tactical_analysis_gk_filtered(model, failure_case, device, gk_indices, title=\"PIGNN Analysis: True Negative (FP-only)\")\n",
        "\n",
        "# ==========================================\n",
        "# 3. å®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³\n",
        "# ==========================================\n",
        "# PIGNNãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ï¼ˆCVã§ä½¿ã£ãŸãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ï¼‰\n",
        "model_viz = PIGNNClassifier(in_channels=7, hidden_channels=64).to(device)\n",
        "\n",
        "# CVã§ä¿å­˜ã—ãŸãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "best_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Models/PIGNN_v17_Gate/best_overall_pignn.pth\"\n",
        "if os.path.exists(best_path):\n",
        "    model_viz.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    print(\" å¯è¦–åŒ–ç”¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«æˆåŠŸã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "    # 1. GKå€™è£œã®ç‰¹å®š\n",
        "    print(\"\\n--- GKãƒãƒ¼ãƒ‰ç‰¹å®šãƒ•ã‚§ãƒ¼ã‚º ---\")\n",
        "    gk_nodes = identify_gk_nodes(model_viz, all_data_list, device)\n",
        "    print(f\" identified GK node indices: {gk_nodes}\")\n",
        "    print(\"--------------------------\")\n",
        "\n",
        "    # 2. GKã‚’é™¤å¤–ã—ã¦å¯è¦–åŒ–ã¨FPçµ±è¨ˆã‚’å®Ÿè¡Œ\n",
        "    run_tactical_comparison_gk_filtered(model_viz, all_data_list, device, gk_nodes)\n",
        "else:\n",
        "    print(f\" ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {best_path}\")"
      ],
      "metadata": {
        "id": "C3gzRbH-z2wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def visualize_pignn_final_min_max_with_vel(model, data_item, device, title=\"PIGNN Tactical Analysis\"):\n",
        "    model.eval()\n",
        "    data_item = data_item.to(device)\n",
        "\n",
        "    # --- 1. æ¨è«–ã¨ãƒ‡ãƒ¼ã‚¿æŠ½å‡º ---\n",
        "    with torch.no_grad():\n",
        "        out = model(data_item)\n",
        "        att_weights = model.conv1.last_alpha.cpu().numpy().flatten()\n",
        "        edge_index = data_item.edge_index.cpu().numpy()\n",
        "\n",
        "        prob = torch.exp(out)[0, 1].item()\n",
        "        pred = out.argmax(dim=1).item()\n",
        "        label = data_item.y.item()\n",
        "\n",
        "    # --- 2. åº§æ¨™ã¨é€Ÿåº¦ã®å¾©å…ƒ ---\n",
        "    pos = data_item.pos.cpu().numpy()\n",
        "    # é€Ÿåº¦ã¯ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã® index 2, 3 ã«å…¥ã£ã¦ã„ã‚‹ (px, py, vx, vy, ...)\n",
        "    vel = data_item.x[:, 2:4].cpu().numpy()\n",
        "\n",
        "    pos_plot = np.zeros_like(pos)\n",
        "    pos_plot[:, 0] = pos[:, 0] * 52.5\n",
        "    pos_plot[:, 1] = pos[:, 1] * 34.0\n",
        "\n",
        "    team_ids = data_item.x[:, 6].cpu().numpy() # 0:Home, 1:Away, 2:Ball\n",
        "\n",
        "    # --- 3. ãƒ­ã‚¸ãƒƒã‚¯ï¼šxåº§æ¨™ã®æœ€å¤§ãƒ»æœ€å°ã‚’GKã¨ã—ã¦ç‰¹å®š ---\n",
        "    # é¸æ‰‹ã®ã¿ï¼ˆãƒœãƒ¼ãƒ«ã‚’é™¤å¤–ï¼‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
        "    player_indices = np.where(team_ids != 2.0)[0]\n",
        "    # é¸æ‰‹ã®ä¸­ã§æœ€ã‚‚å·¦(min)ã¨å³(max)ã‚’ç‰¹å®š\n",
        "    idx_min_x = player_indices[np.argmin(pos[player_indices, 0])]\n",
        "    idx_max_x = player_indices[np.argmax(pos[player_indices, 0])]\n",
        "    gk_indices = [idx_min_x, idx_max_x]\n",
        "\n",
        "    print(f\"ğŸ“Œ GKç‰¹å®šï¼ˆxæœ€å°/æœ€å¤§ï¼‰: Node {idx_min_x} & Node {idx_max_x}\")\n",
        "\n",
        "    # --- 4. æç”»è¨­å®š ---\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    ax.set_facecolor('#2e7d32')\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=True, color='#388e3c', zorder=0))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=False, color='white', lw=3, zorder=1))\n",
        "    ax.plot([0, 0], [-34, 34], color='white', lw=3, zorder=1)\n",
        "    ax.add_patch(patches.Circle((0, 0), 9.15, edgecolor=\"white\", facecolor=\"none\", lw=3, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "    ax.add_patch(patches.Rectangle((52.5-16.5, -20.15), 16.5, 40.3, fill=False, color='white', lw=2, zorder=1))\n",
        "\n",
        "    # --- 5. ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ä¿‚æ•°ã®æç”» (GKé™¤å¤–) ---\n",
        "    active_att_values = [att_weights[i] for i in range(len(att_weights))\n",
        "                         if edge_index[0, i] not in gk_indices and edge_index[1, i] not in gk_indices]\n",
        "\n",
        "    if active_att_values:\n",
        "        threshold = np.percentile(active_att_values, 95)\n",
        "        max_att = np.max(active_att_values)\n",
        "        for i in range(len(att_weights)):\n",
        "            src, dst = edge_index[0, i], edge_index[1, i]\n",
        "            if src in gk_indices or dst in gk_indices: continue\n",
        "\n",
        "            weight = att_weights[i]\n",
        "            if weight >= threshold:\n",
        "                alpha_val = (weight - threshold) / (max_att - threshold + 1e-9)\n",
        "                ax.plot([pos_plot[src, 0], pos_plot[dst, 0]],\n",
        "                        [pos_plot[src, 1], pos_plot[dst, 1]],\n",
        "                        color='#FFFF00', alpha=min(1.0, alpha_val * 1.5),\n",
        "                        lw=1.5 + alpha_val*6, zorder=2)\n",
        "\n",
        "    # --- 6. é¸æ‰‹ãƒ»é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ«ã®æç”» ---\n",
        "    vel_scale = 10.0\n",
        "    for i in range(len(pos_plot)):\n",
        "        is_gk = i in gk_indices\n",
        "        if is_gk:\n",
        "            color, alpha, z = 'gray', 0.2, 5\n",
        "        elif team_ids[i] == 2.0: # ãƒœãƒ¼ãƒ«\n",
        "            color, alpha, z = 'gold', 1.0, 20\n",
        "        elif team_ids[i] == 0.0: # Home\n",
        "            color, alpha, z = '#0288d1', 1.0, 15\n",
        "        else: # Away\n",
        "            color, alpha, z = '#d32f2f', 1.0, 15\n",
        "\n",
        "        # é€Ÿåº¦ãƒ™ã‚¯ãƒˆãƒ« (GKä»¥å¤–ã®FPã®ã¿æç”»)\n",
        "        if not is_gk and team_ids[i] != 2.0:\n",
        "            ax.quiver(pos_plot[i, 0], pos_plot[i, 1],\n",
        "                      vel[i, 0], vel[i, 1],\n",
        "                      color='white', alpha=0.7, angles='xy', scale_units='xy',\n",
        "                      scale=1/vel_scale, width=0.004, zorder=20)\n",
        "\n",
        "        # é¸æ‰‹ãƒãƒ¼ãƒ‰\n",
        "        ax.scatter(pos_plot[i, 0], pos_plot[i, 1], c=color, alpha=alpha, s=350,\n",
        "                   marker='o' if team_ids[i] != 2.0 else '*',\n",
        "                   edgecolors='white', linewidth=1.5, zorder=z)\n",
        "\n",
        "    # --- ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º ---\n",
        "    res_text = \"SUCCESS\" if pred == 1 else \"FAILURE\"\n",
        "    match_status = \"CORRECT\" if label == pred else \"INCORRECT\"\n",
        "    ax.set_title(f\"{title}\\nActual: {'SUCCESS' if label==1 else 'FAILURE'} | Predicted: {res_text} ({prob:.1%})\\nResult: {match_status}\",\n",
        "                 fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "    ax.set_xlim(-60, 60); ax.set_ylim(-40, 40)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "visualize_pignn_final_min_max_with_vel(model_viz, viz_success_case, device)"
      ],
      "metadata": {
        "id": "ccQEe0dz07Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å¤±æ•—ã‚·ãƒ¼ãƒ³ï¼ˆãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãã€Œå¤±æ•—ã€ã¨äºˆæ¸¬ã—ãŸã‚±ãƒ¼ã‚¹ï¼‰ã®æç”»\n",
        "if viz_failure_case is not None:\n",
        "    print(\"ğŸ¬ å¤±æ•—ã‚·ãƒ¼ãƒ³ (True Negative) ã®æç”»ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
        "    visualize_pignn_final_min_max_with_vel(\n",
        "        model_viz,\n",
        "        viz_failure_case,\n",
        "        device,\n",
        "        title=\"PIGNN Tactical Analysis: True Negative (Failure)\"\n",
        "    )\n",
        "else:\n",
        "    print(\" å¤±æ•—ã‚·ãƒ¼ãƒ³ã®ã‚µãƒ³ãƒ—ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æŠ½å‡ºãƒ«ãƒ¼ãƒ—ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\")"
      ],
      "metadata": {
        "id": "Bs-i5SFD2VnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "def run_pignn_pfi(model, data_list, device):\n",
        "    model.eval()\n",
        "    # 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç²¾åº¦ã®è¨ˆç®— (F1ã‚¹ã‚³ã‚¢ãªã©ã‚’æŒ‡æ¨™ã«ã™ã‚‹)\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_list:\n",
        "            d_gpu = data.to(device)\n",
        "            out = model(d_gpu)\n",
        "            y_true.append(d_gpu.y.item())\n",
        "            y_pred.append(out.argmax(dim=1).item())\n",
        "\n",
        "    # ç°¡å˜ã®ãŸã‚ã€ä»Šå›ã¯Accuracyï¼ˆæ­£è§£ç‡ï¼‰ã®ä½ä¸‹å¹…ã§è¨ˆç®—ã—ã¾ã™\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    baseline_acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\" Baseline Accuracy: {baseline_acc:.4f}\")\n",
        "\n",
        "    # ç‰¹å¾´é‡ã®åå‰ãƒªã‚¹ãƒˆ (in_channels=7 ã®å†…è¨³)\n",
        "    feature_names = ['x', 'y', 'vx', 'vy', 'dist_to_ball', 'angle_to_goal', 'team_id']\n",
        "    results = []\n",
        "\n",
        "    for feat_idx in range(len(feature_names)):\n",
        "        shuffled_preds = []\n",
        "\n",
        "        # 2. ç‰¹å®šã®ç‰¹å¾´é‡ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦ç²¾åº¦ã‚’å†æ¸¬å®š\n",
        "        for data in data_list:\n",
        "            # ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ\n",
        "            data_shuffled = copy.deepcopy(data).to(device)\n",
        "\n",
        "            # ãƒãƒ¼ãƒ‰å˜ä½ã§è©²å½“ã™ã‚‹ç‰¹å¾´é‡ã ã‘ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«\n",
        "            perm = torch.randperm(data_shuffled.x.size(0))\n",
        "            data_shuffled.x[:, feat_idx] = data_shuffled.x[perm, feat_idx]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = model(data_shuffled)\n",
        "                shuffled_preds.append(out.argmax(dim=1).item())\n",
        "\n",
        "        shuffled_acc = accuracy_score(y_true, shuffled_preds)\n",
        "        importance = baseline_acc - shuffled_acc # ä½ä¸‹å¹…ãŒé‡è¦åº¦\n",
        "        results.append({'feature': feature_names[feat_idx], 'importance': importance})\n",
        "        print(f\" {feature_names[feat_idx]:<15} | Importance: {importance:.4f}\")\n",
        "\n",
        "    # 3. çµæœã®å¯è¦–åŒ–\n",
        "    df_pfi = pd.DataFrame(results).sort_values(by='importance', ascending=False)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='importance', y='feature', data=df_pfi, palette='viridis')\n",
        "    plt.title(\"PIGNN Permutation Feature Importance\")\n",
        "    plt.xlabel(\"Decrease in Accuracy (Baseline - Shuffled)\")\n",
        "    plt.show()\n",
        "    return df_pfi\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "df_pfi_results = run_pignn_pfi(model_viz, all_data_list, device)"
      ],
      "metadata": {
        "id": "N9JvL_Su22eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from torch_geometric.explain import Explainer, GNNExplainer\n",
        "\n",
        "# ==========================================\n",
        "# 1. ç‰©ç†æ•´åˆæ€§å®Œå…¨å¯¾å¿œãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹\n",
        "# ==========================================\n",
        "class PIGNNExplainerWrapper(torch.nn.Module):\n",
        "    def __init__(self, model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, x, edge_index, **kwargs):\n",
        "        # å®Ÿè¡Œæ™‚ã« AttributeError ãŒå‡ºãªã„ã‚ˆã†ã€ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã¨ã™ã‚‹å…¨ã¦ã®å±æ€§ã‚’æŒã¤\n",
        "        # æ“¬ä¼¼Dataã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
        "        class DataContainer:\n",
        "            pass\n",
        "\n",
        "        data = DataContainer()\n",
        "        data.x = x\n",
        "        data.edge_index = edge_index\n",
        "        data.batch = kwargs.get('batch', torch.zeros(x.size(0), dtype=torch.long, device=x.device))\n",
        "\n",
        "        # PIGNNClassifierãŒå¿…è¦ã¨ã™ã‚‹3ã¤ã®æ™‚ç³»åˆ—åº§æ¨™\n",
        "        data.pos = kwargs.get('pos', None)\n",
        "        data.prev_pos = kwargs.get('prev_pos', None)\n",
        "        # ã‚¨ãƒ©ãƒ¼ã®åŸå› ï¼špprev_posãŒä¸è¶³ã—ã¦ã„ãŸã®ã§ã€kwargsã¾ãŸã¯data_singleã‹ã‚‰å–å¾—\n",
        "        data.pprev_pos = kwargs.get('pprev_pos', None)\n",
        "\n",
        "        # ãƒ¢ãƒ‡ãƒ«ã«æŠ•ã’ã‚‹\n",
        "        return self.model(data)\n",
        "\n",
        "# ãƒ©ãƒƒãƒ—ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ\n",
        "wrapped_model = PIGNNExplainerWrapper(model_viz)\n",
        "\n",
        "# ==========================================\n",
        "# 2. Explainerã®è¨­å®š\n",
        "# ==========================================\n",
        "explainer = Explainer(\n",
        "    model=wrapped_model,\n",
        "    algorithm=GNNExplainer(epochs=200),\n",
        "    explanation_type='model',\n",
        "    node_mask_type='attributes',\n",
        "    edge_mask_type='object',\n",
        "    model_config=dict(\n",
        "        mode='multiclass_classification',\n",
        "        task_level='graph',\n",
        "        return_type='log_probs',\n",
        "    ),\n",
        ")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆpprev_posã‚‚å«ã‚ã¦to(device)ã™ã‚‹ï¼‰\n",
        "data_single = viz_success_case.to(device)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "print(\" GNNExplainerå®Ÿè¡Œä¸­ï¼ˆç‰©ç†ã‚²ãƒ¼ãƒˆå…¨æƒ…å ±ã‚’ä½¿ç”¨ï¼‰...\")\n",
        "explanation = explainer(\n",
        "    x=data_single.x,\n",
        "    edge_index=data_single.edge_index,\n",
        "    batch=torch.zeros(data_single.x.size(0), dtype=torch.long, device=device),\n",
        "    pos=data_single.pos,\n",
        "    prev_pos=data_single.prev_pos,\n",
        "    pprev_pos=getattr(data_single, 'pprev_pos', None) # å±æ€§ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿æ¸¡ã™\n",
        ")\n",
        "print(\" è¨ˆç®—å®Œäº†ã€‚\")\n",
        "\n",
        "# --- æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º ---\n",
        "labels = ['PosX', 'PosY', 'VelX', 'VelY', 'DistBall', 'AngleGoal', 'Team']\n",
        "feat_importance = explanation.node_mask.abs().sum(dim=0).cpu().numpy()\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, feat_importance, color='skyblue', edgecolor='navy')\n",
        "plt.title(\"GNNExplainer Feature Importance (PIGNN)\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# --- ãƒ”ãƒƒãƒä¸Šå¯è¦–åŒ– ---\n",
        "def visualize_tactical_gnn_final(explanation, data):\n",
        "    pos = data.pos.cpu().numpy()\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "    edge_mask = explanation.edge_mask.cpu().numpy()\n",
        "    team_ids = data.x[:, 6].cpu().numpy()\n",
        "\n",
        "    pos_x, pos_y = pos[:, 0] * 52.5, pos[:, 1] * 34.0\n",
        "\n",
        "    # GKç‰¹å®š\n",
        "    player_idx = np.where(team_ids != 2.0)[0]\n",
        "    gk_idx = [player_idx[np.argmin(pos[player_idx, 0])], player_idx[np.argmax(pos[player_idx, 0])]]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.set_facecolor('#2e7d32')\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=True, color='#388e3c', zorder=0))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=False, color='white', lw=3))\n",
        "    ax.plot([0, 0], [-34, 34], color='white', lw=3)\n",
        "\n",
        "    # é‡è¦ã‚¨ãƒƒã‚¸ (ä¸Šä½2%)\n",
        "    threshold = np.percentile(edge_mask, 98)\n",
        "    for i in range(len(edge_mask)):\n",
        "        src, dst = edge_index[0, i], edge_index[1, i]\n",
        "        if src in gk_idx or dst in gk_idx: continue\n",
        "        if edge_mask[i] >= threshold:\n",
        "            ax.plot([pos_x[src], pos_x[dst]], [pos_y[src], pos_y[dst]],\n",
        "                    color='yellow', alpha=0.7, lw=2 + 6*(edge_mask[i]/edge_mask.max()), zorder=2)\n",
        "\n",
        "    # é¸æ‰‹ãƒ»ãƒœãƒ¼ãƒ«\n",
        "    for i in range(len(pos)):\n",
        "        color = 'gray' if i in gk_idx else ('gold' if team_ids[i]==2.0 else ('#0288d1' if team_ids[i]==0.0 else '#d32f2f'))\n",
        "        ax.scatter(pos_x[i], pos_y[i], c=color, s=350, edgecolors='white', zorder=3, alpha=0.3 if i in gk_idx else 1.0)\n",
        "    plt.title(\"GNNExplainer: Tactical Subgraph Analysis\", fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "visualize_tactical_gnn_final(explanation, data_single)"
      ],
      "metadata": {
        "id": "73rs5DSX4JLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ï¼ˆpprev_posã‚‚å«ã‚ã¦to(device)ã™ã‚‹ï¼‰\n",
        "data_single = viz_failure_case.to(device)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "print(\" GNNExplainerå®Ÿè¡Œä¸­ï¼ˆç‰©ç†ã‚²ãƒ¼ãƒˆå…¨æƒ…å ±ã‚’ä½¿ç”¨ï¼‰...\")\n",
        "explanation = explainer(\n",
        "    x=data_single.x,\n",
        "    edge_index=data_single.edge_index,\n",
        "    batch=torch.zeros(data_single.x.size(0), dtype=torch.long, device=device),\n",
        "    pos=data_single.pos,\n",
        "    prev_pos=data_single.prev_pos,\n",
        "    pprev_pos=getattr(data_single, 'pprev_pos', None) # å±æ€§ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿æ¸¡ã™\n",
        ")\n",
        "print(\" è¨ˆç®—å®Œäº†ã€‚\")\n",
        "\n",
        "# --- æ£’ã‚°ãƒ©ãƒ•è¡¨ç¤º ---\n",
        "labels = ['PosX', 'PosY', 'VelX', 'VelY', 'DistBall', 'AngleGoal', 'Team']\n",
        "feat_importance = explanation.node_mask.abs().sum(dim=0).cpu().numpy()\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, feat_importance, color='skyblue', edgecolor='navy')\n",
        "plt.title(\"GNNExplainer Feature Importance (PIGNN)\", fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# --- ãƒ”ãƒƒãƒä¸Šå¯è¦–åŒ– ---\n",
        "def visualize_tactical_gnn_final(explanation, data):\n",
        "    pos = data.pos.cpu().numpy()\n",
        "    edge_index = data.edge_index.cpu().numpy()\n",
        "    edge_mask = explanation.edge_mask.cpu().numpy()\n",
        "    team_ids = data.x[:, 6].cpu().numpy()\n",
        "\n",
        "    pos_x, pos_y = pos[:, 0] * 52.5, pos[:, 1] * 34.0\n",
        "\n",
        "    # GKç‰¹å®š\n",
        "    player_idx = np.where(team_ids != 2.0)[0]\n",
        "    gk_idx = [player_idx[np.argmin(pos[player_idx, 0])], player_idx[np.argmax(pos[player_idx, 0])]]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.set_facecolor('#2e7d32')\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=True, color='#388e3c', zorder=0))\n",
        "    ax.add_patch(patches.Rectangle((-52.5, -34), 105, 68, fill=False, color='white', lw=3))\n",
        "    ax.plot([0, 0], [-34, 34], color='white', lw=3)\n",
        "\n",
        "    # é‡è¦ã‚¨ãƒƒã‚¸ (ä¸Šä½2%)\n",
        "    threshold = np.percentile(edge_mask, 98)\n",
        "    for i in range(len(edge_mask)):\n",
        "        src, dst = edge_index[0, i], edge_index[1, i]\n",
        "        if src in gk_idx or dst in gk_idx: continue\n",
        "        if edge_mask[i] >= threshold:\n",
        "            ax.plot([pos_x[src], pos_x[dst]], [pos_y[src], pos_y[dst]],\n",
        "                    color='yellow', alpha=0.7, lw=2 + 6*(edge_mask[i]/edge_mask.max()), zorder=2)\n",
        "\n",
        "    # é¸æ‰‹ãƒ»ãƒœãƒ¼ãƒ«\n",
        "    for i in range(len(pos)):\n",
        "        color = 'gray' if i in gk_idx else ('gold' if team_ids[i]==2.0 else ('#0288d1' if team_ids[i]==0.0 else '#d32f2f'))\n",
        "        ax.scatter(pos_x[i], pos_y[i], c=color, s=350, edgecolors='white', zorder=3, alpha=0.3 if i in gk_idx else 1.0)\n",
        "    plt.title(\"GNNExplainer: Tactical Subgraph Analysis\", fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "visualize_tactical_gnn_final(explanation, data_single)"
      ],
      "metadata": {
        "id": "trrZ-99j5Xec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã‚ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã‚‹ã¨â€¦\n",
        "\n",
        "ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³:**é †ä¼æ’­ï¼ˆForwardï¼‰**ã®ä¸­é–“å€¤ã€Œè¨ˆç®—ä¸­ã«ã©ã“ã‚’é€šã£ãŸã‹ã€ã¨ã„ã†ãƒ—ãƒ­ã‚»ã‚¹\\n\n",
        "GNNExplainer:**é€†ä¼æ’­ï¼ˆOptimizationï¼‰**ã«ã‚ˆã‚‹è¿‘ä¼¼ã€Œãªãœãã®çµè«–ã«ãªã£ãŸã‹ã€ã¨ã„ã†è«–ç†çš„æ ¹æ‹ \\n\n",
        "\n",
        "PFI**å…¥åŠ›ç ´å£Šï¼ˆPerturbationï¼‰**ã«ã‚ˆã‚‹æ„Ÿåº¦åˆ†æã€Œãã®å¤‰æ•°ãŒã©ã‚Œã ã‘é‡è¦ã‹ã€ã¨ã„ã†çµ±è¨ˆçš„ä¾å­˜åº¦"
      ],
      "metadata": {
        "id": "_ACXU6lB7hfB"
      }
    }
  ]
}