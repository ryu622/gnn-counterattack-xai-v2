{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYINvXwIbkSyMV8HV/Msf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryu622/gnn-counterattack-xai-v2/blob/exp%2Fadd-new-file/GNN_CounterAttack_Thesis_show.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GATにアテンションの可視化を組み込んだバージョン"
      ],
      "metadata": {
        "id": "B6Pl1iC5M4Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "前提：Permutation Feature Importance (PFI) を採用している 。PFIは、特定の入力特徴量がモデルの全体的な性能に与える影響度を測るモデル不可知論的な手法であり 、これにより「速度や角度といった特徴量が全体として重要である」というグローバルな解釈性を提供する 。一方で、特定の反例（例：なぜこの高速なカウンターアタックが失敗に終わったのか）に対して、「どのプレイヤー間の相互作用が決定打となったか」という、詳細でローカルな戦術的洞察を与えるには限界がある。   "
      ],
      "metadata": {
        "id": "vDmDgz2PdQrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets matplotlib pandas scikit-learn spektral tensorflow progressbar ml-insights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8hxJ2dUNlTV",
        "outputId": "269fdd12-3a25-4888-9773-fbe99548a220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.12/dist-packages (7.7.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting progressbar\n",
            "  Downloading progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ml-insights\n",
            "  Downloading ml_insights-1.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets) (3.0.16)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from spektral) (6.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from spektral) (3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from spektral) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from spektral) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Collecting splinecalib>=0.0.13 (from ml-insights)\n",
            "  Downloading splinecalib-0.0.13.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.5.1)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->spektral) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->spektral) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->spektral) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->spektral) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.7)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (5.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.29.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (25.10.0)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.4.0)\n",
            "Downloading spektral-1.3.1-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_insights-1.1.0-py3-none-any.whl (26 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: progressbar, splinecalib\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12065 sha256=302ece129e90e0a6cabdceff69ab0dce22fbe4b0991c5a08173fc139525f7815\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/4d/c7/f3cf0f75c746c219090060131fe00f1523cc2c5484991f4030\n",
            "  Building wheel for splinecalib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for splinecalib: filename=splinecalib-0.0.13-cp312-cp312-linux_x86_64.whl size=2788452 sha256=d812b6163d7cd749557f6adc5ca34d695019d9a0260ec1038013eb0ab94fe09a\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f7/36/a3a01ad624e2432814cb5342c1c4b2d3d8b0c8542c5dca267e\n",
            "Successfully built progressbar splinecalib\n",
            "Installing collected packages: progressbar, jedi, splinecalib, ml-insights, spektral\n",
            "Successfully installed jedi-0.19.2 ml-insights-1.1.0 progressbar-2.5 spektral-1.3.1 splinecalib-0.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install torch_geometric numpy pandas scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ck348RwNn2x",
        "outputId": "a9460e49-d303-4e20-e0d8-5c299c88df0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HejvrxlrMxzB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import numpy as np\n",
        "import pickle\n",
        "import logging\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- ロガーの設定 (元のコードから) ---\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.DEBUG)\n",
        "stdout_handler = logging.StreamHandler(sys.stdout)\n",
        "if not logger.handlers:\n",
        "    logger.addHandler(stdout_handler)\n",
        "\n",
        "# --- 初期設定 (ウィジェット代替) ---\n",
        "class MockDropdown:\n",
        "    def __init__(self, value): self.value = value\n",
        "class MockVBox:\n",
        "    def __init__(self, children): self.children = children\n",
        "class Checkbox:\n",
        "    def __init__(self, value, description): self.value = value; self.description = description\n",
        "\n",
        "adj_matrix = MockDropdown('normal')\n",
        "edge_f_box = MockVBox([Checkbox(value=True, description='Player Distance')] * 6)\n",
        "node_f_box = MockVBox([Checkbox(value=True, description='x coordinate')] * 12)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- データロード (Google Driveから) ---\n",
        "# 実行前にGoogle Driveのマウントが必要です\n",
        "# file_path は '/content/drive/MyDrive/RAW_DATA/women.pkl' のような絶対パスを指す変数\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "file_path = '/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data/women.pkl'\n",
        "\n",
        "\n",
        "logger.info(f\"Opening {file_path}...\")\n",
        "with open(file_path, 'rb') as handle:\n",
        "    og_data = pickle.load(handle)\n",
        "logger.info(\"データロード完了。\")\n",
        "\n",
        "# --- 2. 特徴量フィルタリング (セクション 2.6) ---\n",
        "def filter_features(data, gender=None):\n",
        "    edge_feature_idxs = [idx for idx, x in enumerate(edge_f_box.children) if x.value]\n",
        "    node_feature_idxs = [idx for idx, x in enumerate(node_f_box.children) if x.value]\n",
        "    global node_features\n",
        "    # ノード特徴量の名前を定義 (ここでは簡易的にダミーで置き換える)\n",
        "    #node_features = [f\"Feature_{i}\" for i in range(len(node_feature_idxs))]\n",
        "    CORRECT_NODE_FEATURES = [\n",
        "        \"X Coordinate\",           # 0\n",
        "        \"Y Coordinate\",           # 1\n",
        "        \"vX\",                     # 2\n",
        "        \"vY\",                     # 3\n",
        "        \"Speed\",                  # 4\n",
        "        \"Velocity Angle\",         # 5\n",
        "        \"Distance to Goal\",       # 6\n",
        "        \"Angle with Goal\",        # 7\n",
        "        \"Distance to Ball\",       # 8\n",
        "        \"Angle with Ball\",        # 9\n",
        "        \"Time in Possession\",     # 10\n",
        "        \"Is Ball Carrier\"         # 11\n",
        "    ]\n",
        "    # 修正: ダミー名の代わりに、インデックスに基づいて正しい特徴量名を取得\n",
        "    node_features = [CORRECT_NODE_FEATURES[i] for i in node_feature_idxs]\n",
        "    mat_type = adj_matrix.value\n",
        "    data[mat_type]['e'] = [x[:, edge_feature_idxs] for x in data[mat_type]['e']]\n",
        "    data[mat_type]['x'] = [x[:, node_feature_idxs] for x in data[mat_type]['x']]\n",
        "    return data\n",
        "\n",
        "data = filter_features(og_data.copy())\n",
        "print(\"特徴量のフィルタリング完了。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1-CkFptNHfy",
        "outputId": "ff088923-4cec-496a-f39c-c5daa38bb335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Opening /content/drive/MyDrive/GNN_Football_Analysis/Raw_Data/women.pkl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Opening /content/drive/MyDrive/GNN_Football_Analysis/Raw_Data/women.pkl...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データロード完了。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:データロード完了。\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特徴量のフィルタリング完了。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. PyGデータセットクラスの定義と変換 ---\n",
        "class PyG_CounterDataset(Dataset):\n",
        "    def __init__(self, data, matrix_type, root=None, transform=None, pre_transform=None):\n",
        "        self.raw_data = data\n",
        "        self.matrix_type = matrix_type\n",
        "        self._data_list = self.process_data()\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "    def process_data(self):\n",
        "        data_mat = self.raw_data[self.matrix_type]\n",
        "        data_list = []\n",
        "\n",
        "        for x_np, a_np, e_np, y_np in tqdm(zip(\n",
        "            data_mat['x'], data_mat['a'], data_mat['e'], self.raw_data['binary']\n",
        "        ), total=len(data_mat['x']), desc=\"Converting to PyG Data\"):\n",
        "\n",
        "            try:\n",
        "                if x_np.shape[0] == 0: continue\n",
        "\n",
        "                # 疎行列の修正: SciPyの疎行列を密行列に変換\n",
        "                if hasattr(a_np, 'todense'): a_np = a_np.todense()\n",
        "\n",
        "                # テンソルへの変換\n",
        "                x = torch.tensor(x_np, dtype=torch.float)\n",
        "                a = torch.tensor(a_np, dtype=torch.float)\n",
        "                e = torch.tensor(e_np, dtype=torch.float)\n",
        "                y = torch.tensor(y_np, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "                edge_index, _ = dense_to_sparse(a)\n",
        "\n",
        "                if edge_index.numel() == 0: continue\n",
        "\n",
        "                # エッジ特徴量の整合性チェック\n",
        "                edge_attr = e if e.size(0) == edge_index.size(1) else None\n",
        "\n",
        "                data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        return data_list\n",
        "\n",
        "    def len(self): return len(self._data_list)\n",
        "    def get(self, idx): return self._data_list[idx]\n",
        "\n",
        "dataset_pyg = PyG_CounterDataset(data=data, matrix_type='normal')\n",
        "print(f\" PyTorch Geometricデータセットの変換が完了しました。全サンプル数: {len(dataset_pyg)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50aABw3rNQ_-",
        "outputId": "6d45fbe2-709d-4067-9201-3bbf7ddad47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting to PyG Data: 100%|██████████| 4348/4348 [00:00<00:00, 7837.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PyTorch Geometricデータセットの変換が完了しました。全サンプル数: 4348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. PyG_GNN_Attn クラスの定義 ---\n",
        "# PyG_GNN_Attn は PyG_GNN と同じアーキテクチャですが、アテンション値を返す機能を追加しています。\n",
        "# ハイパーパラメータの設定 (前のセルで定義された変数を使用)\n",
        "CHANNELS = 32\n",
        "LAYERS = 3\n",
        "ATTN_HEADS = 4\n",
        "N_OUT = 1\n",
        "\n",
        "class PyG_GNN_Attn(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_layers, num_heads, out_channels):\n",
        "        super(PyG_GNN_Attn, self).__init__()\n",
        "\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, dropout=0.5, concat=True)\n",
        "        self.convs = nn.ModuleList([\n",
        "            GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, dropout=0.5, concat=True)\n",
        "            for _ in range(num_layers - 1)\n",
        "        ])\n",
        "        self.conv_out = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, dropout=0.5, concat=False)\n",
        "\n",
        "        self.dense1 = nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.dense_out = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data, return_attn=False):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        attn_weights = None\n",
        "\n",
        "        # 最初のGAT層でのみアテンションを抽出\n",
        "        if return_attn:\n",
        "            x, (edge_index, attn_weights) = self.conv1(x, edge_index, return_attention_weights=True)\n",
        "        else:\n",
        "            x = self.conv1(x, edge_index)\n",
        "\n",
        "        x = F.elu(x)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = F.elu(conv(x, edge_index))\n",
        "\n",
        "        x = F.elu(self.conv_out(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        x = F.relu(self.dense1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        output = torch.sigmoid(self.dense_out(x))\n",
        "\n",
        "        if return_attn:\n",
        "            return output, edge_index, attn_weights.squeeze()\n",
        "\n",
        "        return output\n",
        "\n",
        "# --- 2. モデルのインスタンス化と重みコピー ---\n",
        "# model_pyg (訓練済みモデル) が既にメモリに存在することを前提とします。\n",
        "model_attn = PyG_GNN_Attn(\n",
        "    in_channels=dataset_pyg.num_node_features, hidden_channels=CHANNELS, num_layers=LAYERS,\n",
        "    num_heads=ATTN_HEADS, out_channels=N_OUT\n",
        ")\n",
        "model_attn.load_state_dict(model_pyg.state_dict())\n",
        "model_attn.eval()\n",
        "\n",
        "# --- 3. アテンション抽出のためのデータ準備 ---\n",
        "# dataset_te_pyg は前のステップで定義されたテストデータセットです。\n",
        "sample_index = 0\n",
        "single_frame = dataset_te_pyg[sample_index]\n",
        "single_data = single_frame.to(next(model_attn.parameters()).device)\n",
        "\n",
        "# --- 4. アテンション値の抽出を実行 ---\n",
        "with torch.no_grad():\n",
        "    prediction, edge_index_attn, weights_attn = model_attn(single_data, return_attn=True)\n",
        "\n",
        "print(\"アテンション抽出の準備完了。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "b8fYTlF8NUDm",
        "outputId": "1f3f7210-8014-480d-95a2-178bd62b5ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_pyg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1532413656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mATTN_HEADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_OUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mmodel_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pyg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0mmodel_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_pyg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- メイン訓練ループの実行 ---\n",
        "print(\"\\n PyTorch GATモデルの訓練を開始します...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    loss = train_pyg(model_pyg, loader_tr_pyg, optimizer_pyg, criterion)\n",
        "    print(f\"--- Epoch {epoch}/{EPOCHS} --- Loss: {loss:.4f}\")\n",
        "\n",
        "print(\"PyTorch GATモデルの訓練が完了しました。\")"
      ],
      "metadata": {
        "id": "bQOZIB5NNba9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#評価関数の定義\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_pyg(model, loader):\n",
        "    \"\"\"\n",
        "    テストデータローダーを使用してモデルを評価し、AUCとAccuracyを計算する。\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data)\n",
        "            all_preds.append(out.cpu().numpy())\n",
        "            all_labels.append(data.y.cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(all_preds).flatten()\n",
        "    labels = np.concatenate(all_labels).flatten()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, preds)\n",
        "    except ValueError:\n",
        "        auc = np.nan\n",
        "        print(\" Warning: テストセットに単一クラスのみ含まれるため、AUCは未定義です。\")\n",
        "\n",
        "    predicted_classes = (preds > 0.5).astype(int)\n",
        "    accuracy = accuracy_score(labels, predicted_classes)\n",
        "\n",
        "    return auc, accuracy\n",
        "\n",
        "print(\"評価関数 'evaluate_pyg' が定義されました。\")"
      ],
      "metadata": {
        "id": "dJ01TzpFQWJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 評価の実行\n",
        "\n",
        "auc_te, acc_te = evaluate_pyg(model_pyg, loader_te_pyg_clean)\n",
        "\n",
        "print(f\"\\n--- 最終テスト結果 (PyTorch GAT) ---\")\n",
        "print(f\"Test AUC: {auc_te:.4f}\")\n",
        "print(f\"Test Accuracy: {acc_te:.4f}\")"
      ],
      "metadata": {
        "id": "BK7j6A05N3sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#キャリブレーション\n",
        "from sklearn.calibration import calibration_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- キャリブレーションデータの取得 ---\n",
        "def get_calibration_data(model, loader, n_bins=10):\n",
        "    \"\"\"モデルの予測確率と真のラベルを取得し、キャリブレーション曲線のデータを計算する\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data)\n",
        "            all_preds.append(out.cpu().numpy())\n",
        "            all_labels.append(data.y.cpu().numpy())\n",
        "\n",
        "    preds = np.concatenate(all_preds).flatten()\n",
        "    labels = np.concatenate(all_labels).flatten()\n",
        "\n",
        "    # scikit-learnのcalibration_curveを使用してデータを計算\n",
        "    # prob_true: 各ビンの実際の正答率 (y軸)\n",
        "    # prob_pred: 各ビンの平均予測確率 (x軸)\n",
        "    prob_true, prob_pred = calibration_curve(\n",
        "        y_true=labels,\n",
        "        y_prob=preds,\n",
        "        n_bins=n_bins,\n",
        "        strategy='uniform' # 均一な幅のビンを使用\n",
        "    )\n",
        "\n",
        "    return prob_true, prob_pred, preds, labels\n",
        "\n",
        "# --- 実行と描画 ---\n",
        "prob_true, prob_pred, preds_te, labels_te = get_calibration_data(model_pyg, loader_te_pyg_clean)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "# モデルのキャリブレーション曲線\n",
        "plt.plot(prob_pred, prob_true, marker='o', label='PyTorch GAT Model')\n",
        "# 理想的なキャリブレーション (対角線)\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
        "\n",
        "plt.xlabel('Average Predicted Probability (Confidence)')\n",
        "plt.ylabel('Fraction of Positives (Accuracy)')\n",
        "plt.title('Calibration Curve on Test Set')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(\"キャリブレーション曲線の描画が完了しました。\")\n",
        "# 理想的な対角線に近ければ近いほど、モデルの予測は「正直」であると評価できます。"
      ],
      "metadata": {
        "id": "dGZPR7xDN6Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PFI\n",
        "# --- 特徴量重要度の計算 ---\n",
        "# 特徴量の名前は filter_features 関数で定義されたグローバル変数 node_features を使用します\n",
        "global node_features # 以前のステップで定義されています\n",
        "\n",
        "def calculate_permutation_importance(model, loader, features_list, n_repeats=5):\n",
        "    \"\"\"テストデータセット上で、各特徴量のパーミュテーション重要度 (AUCの低下) を計算する\"\"\"\n",
        "\n",
        "    # 1. ベースラインAUCの計算\n",
        "    auc, _ = evaluate_pyg(model, loader)\n",
        "    baseline_auc = auc\n",
        "\n",
        "    importance = {}\n",
        "\n",
        "    # 2. 各特徴量に対して重要度を測定\n",
        "    for idx, feature_name in enumerate(features_list):\n",
        "        auc_decreases = []\n",
        "\n",
        "        for _ in range(n_repeats):\n",
        "            # 2.1. テストローダー内の全グラフをパーミュテーション処理\n",
        "            permuted_data_list = []\n",
        "            for batch_data in loader:\n",
        "                # バッチ内のノード特徴量 x のコピーを作成\n",
        "                x_permuted = batch_data.x.clone()\n",
        "\n",
        "                # 特定の特徴量列 (idx) をランダムに入れ替え (パーミュテーション)\n",
        "                # バッチ全体でランダムに行うのが一般的\n",
        "                perm_indices = torch.randperm(x_permuted.size(0))\n",
        "                x_permuted[:, idx] = x_permuted[perm_indices, idx]\n",
        "\n",
        "                # 新しいxでデータオブジェクトを再構築 (バッチ構造を維持)\n",
        "                permuted_batch = batch_data.clone()\n",
        "                permuted_batch.x = x_permuted\n",
        "                permuted_data_list.append(permuted_batch)\n",
        "\n",
        "            # 2.2. パーミュテーション後のAUCを評価\n",
        "            # Note: PyGDataLoaderはリストを受け取るため、ここで新しいDataLoaderを一時的に使用します\n",
        "            permuted_loader = PyGDataLoader(permuted_data_list, batch_size=loader.batch_size, shuffle=False)\n",
        "            permuted_auc, _ = evaluate_pyg(model, permuted_loader)\n",
        "            auc_decreases.append(baseline_auc - permuted_auc)\n",
        "\n",
        "        # 2.3. 平均低下量を格納\n",
        "        importance[feature_name] = np.mean(auc_decreases)\n",
        "\n",
        "    return importance\n",
        "\n",
        "# --- 実行と描画 ---\n",
        "\n",
        "# 注意: n_repeatsが多いほど精度が上がりますが、計算時間がかかります。\n",
        "importance_results = calculate_permutation_importance(model_pyg, loader_te_pyg_clean, node_features, n_repeats=1) # まずは n_repeats=1 で試します\n",
        "\n",
        "# 結果をソートして表示\n",
        "sorted_importance = sorted(importance_results.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "print(\"\\n--- 特徴量重要度 (AUC低下量) ---\")\n",
        "for feature, decrease in sorted_importance:\n",
        "    print(f\"[{feature: <20}] : {decrease:.5f}\")\n",
        "\n",
        "# 棒グラフで視覚化\n",
        "features = [item[0] for item in sorted_importance]\n",
        "decreases = [item[1] for item in sorted_importance]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(features, decreases, color='skyblue')\n",
        "plt.xlabel('AUC Decrease after Permutation')\n",
        "plt.title('Permutation Feature Importance (PyTorch GAT)')\n",
        "plt.gca().invert_yaxis() # 最も重要な特徴量を上に表示\n",
        "plt.grid(axis='x', linestyle='--')\n",
        "plt.show()\n",
        "\n",
        "print(\"特徴量重要度の計算と描画が完了しました。\")"
      ],
      "metadata": {
        "id": "ccoz0J5FN89J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- 1. アテンション抽出のための変数定義 (前ステップで抽出済みを想定) ---\n",
        "# single_data: テストセットから取得した単一のDataオブジェクト\n",
        "# prediction: モデルの予測確率 (例: 0.48)\n",
        "# edge_index_attn: エッジの接続リスト\n",
        "# weights_attn: 抽出されたアテンション重み (NumPy配列に変換済み)\n",
        "\n",
        "# --- 2. NetworkXグラフの構築と可視化 ---\n",
        "\n",
        "# 1. テンソルをCPU上のNumPy配列に変換\n",
        "# ノード特徴 (選手の座標) - x:0列目, y:1列目と仮定\n",
        "x_coords = single_data.x[:, 0].cpu().numpy()\n",
        "y_coords = single_data.x[:, 1].cpu().numpy()\n",
        "edge_list = edge_index_attn.cpu().numpy().T\n",
        "attention_weights = weights_attn.cpu().numpy()\n",
        "\n",
        "# 2. NetworkXグラフの構築\n",
        "G = nx.Graph()\n",
        "num_nodes = len(x_coords)\n",
        "G.add_nodes_from(range(num_nodes))\n",
        "pos = {i: (x_coords[i], y_coords[i]) for i in range(num_nodes)} # ノード座標\n",
        "\n",
        "# 3. エッジの重み付けと正規化 (描画の太さ用)\n",
        "min_w = attention_weights.min()\n",
        "max_w = attention_weights.max()\n",
        "# NumPy配列として計算。描画の太さ (1〜11の範囲) に調整\n",
        "# ゼロ割を避けるため微小値 (1e-6) を追加\n",
        "normalized_weights_np = 10 * (attention_weights - min_w) / (max_w - min_w + 1e-6) + 1\n",
        "\n",
        "# --- 修正後のグラフ構築部分 ---\n",
        "\n",
        "# --- 修正後のグラフ構築部分 ---\n",
        "\n",
        "# 4. グラフにエッジと重みを追加 (型変換エラー回避のためfloatに明示変換)\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "\n",
        "    # 🚨 最終修正点: NumPyのfloat型を強制的に経由させる\n",
        "    try:\n",
        "        # NumPyのfloat64型に変換し、その値をPythonのfloatとして取得する\n",
        "        # 配列が残る場合でも、この強制変換で処理できるようになる可能性が高い\n",
        "        weight_val = float(np.float64(normalized_weights_np[i]))\n",
        "\n",
        "    except Exception:\n",
        "        # 上記で失敗する場合、以前のコードの最も安全な方法を試みる\n",
        "        weight_val = float(normalized_weights_np[i].flatten()[0])\n",
        "\n",
        "    G.add_edge(u, v, weight=weight_val)\n",
        "\n",
        "# 描画コマンドの実行\n",
        "# --- 5. 可視化の実行コード ---\n",
        "\n",
        "# 1. グラフの構築と重み付け (前のコードブロックで実行されたものと同じロジックを使用)\n",
        "# x_coords, y_coords, prediction, edge_list, G, pos, num_nodes は既に定義済み\n",
        "\n",
        "# エッジの太さを取得\n",
        "# 🚨 ここでエラーが出ないはず：Gに格納された値は、前のループでfloat型に強制変換されているため\n",
        "edge_widths = [G[u][v]['weight'] for u, v in G.edges()]\n",
        "\n",
        "# 可視化の実行\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Local Attention Visualization (Prediction: {prediction.item():.2f})\")\n",
        "\n",
        "# ノード情報 (以前の定義を使用)\n",
        "num_players = 22\n",
        "num_players_per_team = 11\n",
        "node_colors = ['red'] * num_players_per_team + ['blue'] * num_players_per_team + ['yellow']\n",
        "node_sizes = [300] * num_players + [500]\n",
        "\n",
        "# 描画コマンド\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.7, edge_color='black')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ アテンションの可視化描画が完了しました。\")"
      ],
      "metadata": {
        "id": "NQjYSRbrSDL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIによる分析：これは、あなたが PyTorch GAT (グラフアテンションネットワーク) モデルで実行した、特定のカウンターアタックフレームにおけるローカルアテンションの可視化結果です。このグラフは、モデルが予測確率 0.48 (失敗がわずかに優勢) を導き出すために、ピッチ上のどの選手間の相互作用に最も「注目」したかを視覚的に示しています。⚽ グラフの構成要素と初期分析1. ノード（選手とボール）の配置ノード: 赤丸（攻撃側）、青丸（守備側）、黄色（ボール、ID 22）。配置: ボール（ID 22）は、ピッチの中央やや下（低いY座標）に位置しており、攻撃側と守備側の選手がその周辺に密集していることがわかります。ノードID: ノードにはID (0から22) が割り振られており、特定の選手やボールを識別できます。2. アテンション（注目の強さ）エッジの太さ: GATモデルが計算したアテンション係数 ($\\alpha_{ij}$) の強さを表します。線が太いほど、その選手間の情報交換が予測に重要であったことを意味します。2. 🔍 アテンションの主要なパターン分析このフレームでは、予測確率が 0.48 と、成功と失敗が拮抗しています。これは、モデルが**「失敗につながる守備の相互作用」と「成功につながる攻撃の相互作用」**の両方に注目していることを示唆します。🥇 最も強いアテンション（太いエッジ）グラフの中央、ボールの近くに、最も太いエッジが集中しています。ノード 22 (ボール) と周辺選手間の相互作用:ボールと攻撃側選手（例: ID 0, 1, 3, 4）の間、およびボールと守備側選手（例: ID 7, 13, 14, 15）の間で、非常に太いエッジが見られます。解釈: モデルは、ボールを巡る瞬間の攻防、特にボール保持者とマーク役の選手の足元の状況に最大の注意を払っています。守備選手間の協力 (青-青):ノード 13と15、13と14など、守備側の選手同士を結ぶ太いエッジが多数確認できます。解釈: 守備側が密集地帯で効果的に連携を取り、スペースを埋めようとしている相互作用が、モデルの予測（失敗の可能性）に重要であると判断されています。🥈 重要な攻撃的相互作用攻撃選手間の連携 (赤-赤):攻撃側の選手（例: ID 0とID 4、ID 1とID 4）を結ぶ太いエッジが見られます。解釈: これは、ボールの近くでパスの選択肢を作り出したり、次の展開の準備をしたりといった、攻撃側の局所的な連携がモデルにとって重要であることを示します。🥉 周辺のアテンション遠い選手の低アテンション:ピッチのサイドにいる選手（例: 攻撃側 ID 10 や守備側 ID 21）を結ぶエッジは、多くが細いままです。解釈: モデルは、この決定的な瞬間に遠い位置の選手の絶対的な位置や動きは無視し、ボール周辺の密集地帯での相互作用に焦点を絞っていることが裏付けられます。3. 🎯 結論この可視化は、GATモデルがバイナリ予測を行う際、論理的かつ戦術的に適切な判断を下していることを示しています。モデルは、広大なピッチ全体ではなく、ボール周辺の狭い範囲における、複数の選手間の同時発生的な動きやマーク（守備の連携、攻撃の選択肢）に最も注意を払っています。"
      ],
      "metadata": {
        "id": "1VflHgGQXAIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "成功確率が最も高いフレームを抽出してみる"
      ],
      "metadata": {
        "id": "BSxA4ZrhX2V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. 成功確率が最も高いサンプルを見つける ---\n",
        "model_attn.eval()\n",
        "max_pred = -1.0\n",
        "best_index = -1\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, data_frame in enumerate(dataset_te_pyg):\n",
        "        # モデルと同じデバイスに移動\n",
        "        data_frame = data_frame.to(next(model_attn.parameters()).device)\n",
        "\n",
        "        # 予測確率の取得\n",
        "        prediction_prob = model_attn(data_frame).item()\n",
        "\n",
        "        if prediction_prob > max_pred:\n",
        "            max_pred = prediction_prob\n",
        "            best_index = idx\n",
        "\n",
        "print(f\"✅ 最も高い予測確率 {max_pred:.4f} を持つフレームのインデックス: {best_index}\")"
      ],
      "metadata": {
        "id": "ZMzExx_HXURX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 特定フレームのアテンション抽出と可視化 ---\n",
        "\n",
        "# 成功フレームのデータ取得\n",
        "single_frame = dataset_te_pyg[best_index]\n",
        "single_data = single_frame.to(next(model_attn.parameters()).device)\n",
        "\n",
        "# アテンション値の抽出\n",
        "with torch.no_grad():\n",
        "    prediction, edge_index_attn, weights_attn = model_attn(single_data, return_attn=True)\n",
        "\n",
        "print(f\"予測確率: {prediction.item():.2f}\")\n",
        "\n",
        "# 3. NetworkXグラフの構築と可視化 (以前のコードを使用)\n",
        "x_coords = single_data.x[:, 0].cpu().numpy()\n",
        "y_coords = single_data.x[:, 1].cpu().numpy()\n",
        "edge_list = edge_index_attn.cpu().numpy().T\n",
        "attention_weights = weights_attn.cpu().numpy()\n",
        "\n",
        "G = nx.Graph()\n",
        "num_nodes = len(x_coords)\n",
        "G.add_nodes_from(range(num_nodes))\n",
        "pos = {i: (x_coords[i], y_coords[i]) for i in range(num_nodes)}\n",
        "\n",
        "# エッジの重み付けと正規化\n",
        "min_w = attention_weights.min()\n",
        "max_w = attention_weights.max()\n",
        "normalized_weights = 10 * (attention_weights - min_w) / (max_w - min_w + 1e-6) + 1\n",
        "\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "    try:\n",
        "        weight_val = float(normalized_weights[i].squeeze().item())\n",
        "    except Exception:\n",
        "        weight_val = float(normalized_weights[i].flatten()[0])\n",
        "\n",
        "    G.add_edge(u, v, weight=weight_val)\n",
        "\n",
        "# 描画コマンド\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Local Attention Visualization (SUCCESS Prediction: {prediction.item():.2f})\")\n",
        "\n",
        "num_players = 22\n",
        "num_players_per_team = 11\n",
        "node_colors = ['red'] * num_players_per_team + ['blue'] * num_players_per_team + ['yellow']\n",
        "node_sizes = [300] * num_players + [500]\n",
        "\n",
        "edge_widths = [G[u][v]['weight'] for u, v in G.edges()]\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.7, edge_color='black')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "27J0evj8XYmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SaZi_pnKYUQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AIによる分析： 成功フレーム (Prediction: 0.98) の詳細分析1. 🥇 決定的な位置：ゴール前への侵入集中位置の特定: 選手とボールの配置は、ピッチの**右サイド、相手ゴールに近いエリア（高い X 座標）**に極めて集中しています。これは、カウンターアタックが最終局面に入り、得点に最も近い状況にあることを示しています。ボールの位置: ボール（ノード 12、黄色）は、密集地帯の最前線に位置しており、すぐにシュートまたは最後のパスが出せる状況にあることが示唆されます。2. 🧠 アテンションの焦点：攻撃側の連携と優位性このフレームでモデルが最も強く注目しているのは、攻撃側の連携とボールへの集中です。アテンションの種類観察されるパターンモデルの解釈（成功の根拠）ボールと攻撃側 (黄-赤)ノード 12 (ボール) は、ノード 1, 4, 6, 9 など複数の攻撃側選手と非常に太いエッジで接続されています。モデルは、ボール周辺に複数のパスコースやシュートの選択肢が同時に存在している状況を認識しています。これは、守備側がマークを絞りきれない状態であり、成功を確信しています。攻撃側同士 (赤-赤)攻撃側選手同士（例：1-4、5-9、6-8）の間でも太いエッジが多く見られます。これは、攻撃側の選手がお互いの動きを理解し合い、守備ラインの裏や隙間を突くための効果的な動き出しやポジショニングを実行していることに注目していることを示します。遠いノードノード 10 のように、プレーの中心から離れたノードからのエッジは細く、モデルはほとんど無視しています。ローカルアテンションの有効性: モデルは、遠方の選手の動きではなく、得点につながる密集地帯の相互作用に焦点を絞ることで、予測精度を高めています。3. 🛡️ 守備側の対応（相対的な軽視）成功フレームにおいて、モデルは守備側の努力を認識しつつも、攻撃側の脅威度を上回るとは見ていません。青-青のエッジ: 守備側選手（青）同士を結ぶエッジも太いものがありますが、その太さはボールと攻撃側の太いエッジに比べて支配的ではありません。解釈: 守備側は密集し、組織的な対応を試みていますが、GATモデルは、守備側の努力よりも攻撃側の決定的な動きの方が上回っていると判断しています。つまり、守備側が「スペースを埋める」ことよりも、攻撃側が「決定的なスペースを生み出す」ことにアテンションが強く向いています。結論GATモデルは、カウンターアタックの成功を予測する際、**「ゴール前での攻撃側の数的優位性、組織的な連携、そしてシュート/パスの実行可能性」**という、戦術的に正しい決定要因に集中的に注目していることがわかります。成功の瞬間のモデルの「視線」は、ボールとそれを囲む攻撃側の選手間の関係性にロックされていると言えます。"
      ],
      "metadata": {
        "id": "Deq-aNTYYQ60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "成功と失敗の違い\n",
        "GATローカルアテンションの分析1. 🥇 成功予測フレーム (Prediction: 0.98) の分析グラフimage_6f2b52.png (予測: 0.98)状況モデルはカウンターアタックがほぼ確実に成功すると予測しています。ノード配置選手とボールがピッチのゴールに近い右側に集中。ノード 12 (ボール) が相手ゴール前、攻撃側選手（赤）に囲まれています。主要アテンション（太いエッジ）🔴 ボールと攻撃側の接続: ボール（12）と攻撃側選手（1, 4, 9, 6）の間で、非常に太いエッジが集中しています。解釈モデルは、ゴール前での攻撃側の決定的なパス交換や、シュート体勢にある選手の動きに最大の注意を払っています。守備側（青）の選手がゴールを守るために密集していますが、モデルは攻撃側の優位性（太い赤-黄のエッジ）に注目し、予測を確定しています。2. 🥈 失敗予測フレーム (Prediction: 0.48) の分析グラフimage_6f363b.png (予測: 0.48)状況モデルは成功と失敗が拮抗している状態、または失敗がわずかに優勢と予測しています。ノード配置選手とボールがピッチの中央下部に密集しており、ゴールから遠い位置にあります。主要アテンション（太いエッジ）🔵 守備側の連携: 守備側選手（青）同士（例: 4と13, 14, 16）を結ぶエッジが太く、特にボール（22）の周囲で強いです。解釈モデルは、攻撃側がゴールへ向かう前に、守備側が組織的にスペースを埋め、ボールの出口を塞ぐ相互作用に注目しています。太い青-青のエッジは、守備側の効果的なブロックまたはマークが、攻撃を停滞させている（成功確率を下げている）根拠であると示唆しています。3. 🎯 GATが学習した戦術的洞察これら2つのグラフの比較から、GATモデルは以下の戦術的違いを判断基準にしていることがわかります。判断基準成功フレーム (0.98)失敗フレーム (0.48)注目の中心ボールと攻撃側の優位な選手 (ゴール前)ボールと守備側の連携線 (中央密集地)決定的な相互作用赤-黄 (シュート/パスコースが開いている)青-青 (守備側のスペースカバー)GATの結論優位な位置での攻撃的連携が成功を確定させる。守備側の効果的な協力が攻撃を停滞させ、失敗に傾かせる。"
      ],
      "metadata": {
        "id": "FZ62R4mrYYao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 守備側のみの内部連携 (Blue-Blue) ---\n",
        "\n",
        "\n",
        "# ノードIDの範囲を定義\n",
        "DEFENSE_START_ID = 11\n",
        "DEFENSE_END_ID = 21\n",
        "\n",
        "defense_edges = []\n",
        "defense_widths = []\n",
        "\n",
        "# 🚨 修正点: edge_widths[i] ではなく、正規化された重みリストの i 番目の要素を直接参照する\n",
        "# 注: attention_weights または normalized_weights_np がリスト i の長さを持っていると仮定\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "\n",
        "    is_defense_u = (DEFENSE_START_ID <= u <= DEFENSE_END_ID)\n",
        "    is_defense_v = (DEFENSE_START_ID <= v <= DEFENSE_END_ID)\n",
        "\n",
        "    if is_defense_u and is_defense_v:\n",
        "        defense_edges.append((u, v))\n",
        "        # 参照するのは元の正規化された重みリストの i 番目の要素\n",
        "        # weight_val は float() に変換済みであるため、ここでは float を使用します\n",
        "        defense_widths.append(G[u][v]['weight'])\n",
        "        # もし G[u][v]['weight'] が float でない場合は、G.edges(data=True) を使う必要がありますが、\n",
        "        # ここでは G に格納されている 'weight' 属性を直接参照します。\n",
        "\n",
        "# G.edges() を使ってエッジと重みをループで取得するのが最も確実です\n",
        "# ただし、元のロジックに従い、フィルタリングには edge_list を使用します。\n",
        "\n",
        "# 🚨 修正後のロジック (Gに格納された重みを参照):\n",
        "for edge in G.edges(data=True):\n",
        "    u, v, data = edge\n",
        "\n",
        "    is_defense_u = (DEFENSE_START_ID <= u <= DEFENSE_END_ID)\n",
        "    is_defense_v = (DEFENSE_START_ID <= v <= DEFENSE_END_ID)\n",
        "\n",
        "    if is_defense_u and is_defense_v:\n",
        "        defense_edges.append((u, v))\n",
        "        defense_widths.append(data['weight'])\n",
        "\n",
        "# グラフの描画\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"GAT Attention: Defense Team Internal Collaboration (Blue-Blue Edges)\")\n",
        "\n",
        "# ノードは全て描画し、エッジのみをフィルタリング\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=defense_edges, width=defense_widths, alpha=0.9, edge_color='darkblue')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wYTc0pzaZpqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 攻撃側のみの内部連携 (Red-Red) ---\n",
        "\n",
        "# ノードIDの範囲を定義 (攻撃チームはID 0から10と仮定)\n",
        "ATTACK_START_ID = 0\n",
        "ATTACK_END_ID = 10\n",
        "\n",
        "# 攻撃チームのエッジのみをフィルタリングするためのリスト\n",
        "attack_edges = []\n",
        "attack_widths = []\n",
        "\n",
        "# グラフGに格納されているエッジと重みを安全にループ処理\n",
        "for u, v, data in G.edges(data=True):\n",
        "\n",
        "    # 接続元と接続先が両方とも攻撃チームの範囲内にあることを確認\n",
        "    is_attack_u = (ATTACK_START_ID <= u <= ATTACK_END_ID)\n",
        "    is_attack_v = (ATTACK_START_ID <= v <= ATTACK_END_ID)\n",
        "\n",
        "    if is_attack_u and is_attack_v:\n",
        "        # エッジリストに追加\n",
        "        attack_edges.append((u, v))\n",
        "        # 🚨 安全に重み (太さ) を取得\n",
        "        attack_widths.append(data['weight'])\n",
        "\n",
        "# グラフの描画\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"GAT Attention: Attack Team Internal Collaboration (Red-Red Edges)\")\n",
        "\n",
        "# ノードは全て描画し、エッジのみをフィルタリング\n",
        "# (pos, node_sizes, node_colors, G は前のステップで定義されたものを使用)\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=attack_edges, width=attack_widths, alpha=0.9, edge_color='darkred')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "plt.show()\n",
        "\n",
        "print(\"✅ 攻撃側のみの連携グラフ描画が完了しました。\")"
      ],
      "metadata": {
        "id": "c-QYJI_xaAK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🛡️ 守備側のみの連携 (Blue-Blue Edges)グラフimage_6ec271.png (守備側のみ)傾向中央から右側にかけて、守備側選手（青）同士の太いエッジが多数確認される (例: 13-16, 17-21)。分析守備側の組織化: モデルは、この決定的な瞬間に守備側がマークの受け渡しやカバーリング（カバーディフェンス）を行うための内部的な連携に強く注目しています。これは、守備側が数的不利の中で、なんとか組織を維持しようとしている行動が、予測に重要であると判断されたことを示します。結論守備側は諦めておらず、組織を維持しようとする協調性が、予測の重要な情報源となっている。3. ⚔️ 攻撃側のみの連携 (Red-Red Edges)グラフimage_6ec255.png (攻撃側のみ)傾向グラフ全体（特にピッチ中央から右にかけて）にわたり、太く長いエッジが広範囲に確認される (例: 10-6, 7-6)。分析攻撃側の空間支配: ボール周辺だけでなく、**遠くの選手（ノード 10, 7）**とも太いエッジで結ばれています。これは、攻撃側がピッチの深さと幅を広く使い、守備側にタテ・ヨコに広いエリアを守らせることで、守備を分断しようとする戦術にモデルが注目していることを示します。結論成功は、局所的な連携だけでなく、遠くのサポートランやスペースを広げる動きといった、広範な攻撃側の協調性によって支えられている。"
      ],
      "metadata": {
        "id": "WCTr9ZdlagA6"
      }
    }
  ]
}