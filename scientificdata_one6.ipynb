{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryu622/gnn-counterattack-xai-v2/blob/feat%2Fnew-file/scientificdata_one6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "卒論で使用した最終的なデータ前処理コード"
      ],
      "metadata": {
        "id": "_PmKwwpVfhvw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxLtiVge7-0f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnkvNbXz8YoL"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHZPKF7685s3"
      },
      "outputs": [],
      "source": [
        "!pip install floodlight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0mCPYwN8XKO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from collections import defaultdict\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import radius_graph\n",
        "import floodlight.io.dfl as dfl_io\n",
        "\n",
        "# ==========================================\n",
        "# 1. GNNDataBuilder クラス (全メソッド完全・距離閾値グラフ版)\n",
        "# ==========================================\n",
        "class GNNDataBuilder:\n",
        "    def __init__(self):\n",
        "        self.OBSERVATION_WINDOW = 25   # 1秒間の観測（速度算出用）\n",
        "        self.PREDICTION_TARGET = 125   # 5秒後の到達地点を確認\n",
        "        self.dt_velocity = 0.20        # 5フレーム差での速度計算\n",
        "        self.pitch_length_half = 52.5\n",
        "        self.pitch_width_half = 34.0\n",
        "        self.SUCCESS_X_THRESHOLD = 25.0\n",
        "\n",
        "    def extract_sequences(self, df_pos, df_event, match_id_idx, manual_flip, left_team_id):\n",
        "        recovery_types = ['TacklingGame', 'BallClaiming', 'BallDeflection']\n",
        "        recovery_events = df_event[df_event['eID'].isin(recovery_types)]\n",
        "        sequences = []\n",
        "\n",
        "        is_cm = df_pos['Ball_x'].abs().max() > 500\n",
        "        scale = 100.0 if is_cm else 1.0\n",
        "\n",
        "        # Offset補正\n",
        "        max_x_raw = df_pos['Ball_x'].max() / scale\n",
        "        min_x_raw = df_pos['Ball_x'].min() / scale\n",
        "        # 最小値が-30以下ならセンター0系と判断（Match 4対策）\n",
        "        offset_x = 0.0 if min_x_raw < -30 else 52.5\n",
        "\n",
        "        stadium_flip = float(manual_flip)\n",
        "\n",
        "        for idx, event in recovery_events.iterrows():\n",
        "            period = str(event['period'])\n",
        "            striking_team = str(event['tID']).strip()\n",
        "\n",
        "            # --- 物理整合性のためのFlipロジック ---\n",
        "            if period in ['1', 'firstHalf']:\n",
        "                raw_is_attacking_right = (striking_team == left_team_id)\n",
        "            else:\n",
        "                raw_is_attacking_right = (striking_team != left_team_id)\n",
        "\n",
        "            dynamic_flip = (1.0 if raw_is_attacking_right else -1.0) * stadium_flip\n",
        "\n",
        "            # フレーム特定\n",
        "            start_f_raw = int(event['gameclock'] * 25)\n",
        "            potential_start = df_pos[df_pos['frame_idx'] >= start_f_raw].index\n",
        "            if len(potential_start) == 0: continue\n",
        "            start_idx = potential_start[0]\n",
        "            target_idx = start_idx + self.PREDICTION_TARGET\n",
        "            if target_idx >= len(df_pos): continue\n",
        "\n",
        "            # --- ラベル判定 ---\n",
        "            start_x_flipped = ((df_pos.iloc[start_idx]['Ball_x'] / scale) - offset_x) * dynamic_flip\n",
        "            target_x_flipped = ((df_pos.iloc[target_idx]['Ball_x'] / scale) - offset_x) * dynamic_flip\n",
        "\n",
        "            is_in_deep_area = target_x_flipped > self.SUCCESS_X_THRESHOLD\n",
        "            is_progressing = (target_x_flipped - start_x_flipped) > 5.0\n",
        "\n",
        "            label = 1 if (is_in_deep_area and is_progressing) else 0\n",
        "\n",
        "            # 観測ウィンドウ（1秒分）\n",
        "            obs_frames = df_pos.iloc[start_idx : start_idx + self.OBSERVATION_WINDOW].copy()\n",
        "            obs_frames.loc[:, 'offset_x_val'] = float(offset_x)\n",
        "            obs_frames.loc[:, 'flip_factor'] = float(dynamic_flip)\n",
        "            obs_frames.loc[:, 'label'] = int(label)\n",
        "            obs_frames.loc[:, 'SequenceID'] = int(idx + (match_id_idx * 1000))\n",
        "            sequences.append(obs_frames)\n",
        "\n",
        "        return sequences\n",
        "\n",
        "    def to_pyg_data(self, sequences, team_map):\n",
        "        pyg_list = []\n",
        "        if not sequences: return []\n",
        "\n",
        "        is_cm = sequences[0]['Ball_x'].abs().max() > 500\n",
        "        scale = 100.0 if is_cm else 1.0\n",
        "\n",
        "        for seq in sequences:\n",
        "            # 物理ゲート用に3地点を取得\n",
        "            frame_pprev = seq.iloc[-11] # 10枚前 (pprev)\n",
        "            frame_prev  = seq.iloc[-6]  # 5枚前 (prev)\n",
        "            frame_curr  = seq.iloc[-1]  # 現在 (pos)\n",
        "\n",
        "            off_x = frame_curr['offset_x_val']\n",
        "            flip = frame_curr['flip_factor']\n",
        "            label = int(frame_curr['label'])\n",
        "            sid = int(frame_curr['SequenceID'])\n",
        "\n",
        "            def transform_x(raw_val):\n",
        "                return (((raw_val / scale) - off_x) * flip) / self.pitch_length_half\n",
        "            def transform_y(raw_val, y_aug=1.0):\n",
        "                return (((raw_val / scale) * flip) * y_aug) / self.pitch_width_half\n",
        "\n",
        "            for y_aug in [1.0, -1.0]:\n",
        "                node_features, pos_list, prev_pos_list, pprev_pos_list = [], [], [], []\n",
        "\n",
        "                entities = []\n",
        "                for team_prefix in ['Home', 'Away']:\n",
        "                    team_val = 0.0 if team_prefix == 'Home' else 1.0\n",
        "                    for p_id in team_map[team_prefix]:\n",
        "                        entities.append((f\"{p_id}_x\", f\"{p_id}_y\", team_val))\n",
        "                entities.append(('Ball_x', 'Ball_y', 2.0))\n",
        "\n",
        "                for col_x, col_y, t_val in entities:\n",
        "                    if col_x not in frame_curr or pd.isna(frame_curr[col_x]) or frame_curr[col_x] == 0:\n",
        "                        continue\n",
        "\n",
        "                    px, py = transform_x(frame_curr[col_x]), transform_y(frame_curr[col_y], y_aug)\n",
        "                    px_p, py_p = transform_x(frame_prev[col_x]), transform_y(frame_prev[col_y], y_aug)\n",
        "                    px_pp, py_pp = transform_x(frame_pprev[col_x]), transform_y(frame_pprev[col_y], y_aug)\n",
        "\n",
        "                    vx = (px - px_p) / self.dt_velocity\n",
        "                    vy = (py - py_p) / self.dt_velocity\n",
        "\n",
        "                    node_features.append([px, py, vx, vy, 0.0, 0.0, t_val])\n",
        "                    pos_list.append([px, py])\n",
        "                    prev_pos_list.append([px_p, py_p])\n",
        "                    pprev_pos_list.append([px_pp, py_pp])\n",
        "\n",
        "                # テンソル化\n",
        "                x_tensor = torch.tensor(node_features, dtype=torch.float)\n",
        "                pos_tensor = torch.tensor(pos_list, dtype=torch.float)\n",
        "\n",
        "                # ---  手動距離閾値グラフ構築  ---\n",
        "                # r=0.5 (約26m) を閾値とする\n",
        "                r = 0.6\n",
        "                # 全ノード間の距離行列を計算 (形状: [N, N])\n",
        "                dist_matrix = torch.cdist(pos_tensor, pos_tensor, p=2)\n",
        "                # 距離が r 以下かつ自分自身でないインデックスを取得\n",
        "                edge_index = (dist_matrix <= r).nonzero(as_tuple=False).t()\n",
        "                # 自己ループ (i==j) を除去\n",
        "                mask = edge_index[0] != edge_index[1]\n",
        "                edge_index = edge_index[:, mask]\n",
        "\n",
        "                pyg_list.append(Data(\n",
        "                    x=x_tensor,\n",
        "                    edge_index=edge_index,\n",
        "                    y=torch.tensor([label], dtype=torch.long),\n",
        "                    pos=pos_tensor,\n",
        "                    prev_pos=torch.tensor(prev_pos_list, dtype=torch.float),\n",
        "                    pprev_pos=torch.tensor(pprev_pos_list, dtype=torch.float),\n",
        "                    sequence_id=torch.tensor([sid if y_aug == 1.0 else sid + 5000], dtype=torch.long)\n",
        "                ))\n",
        "        return pyg_list\n",
        "\n",
        "# ==========================================\n",
        "# 2. 補助関数の定義\n",
        "# ==========================================\n",
        "def get_match_direction_map(e_path):\n",
        "    tree = ET.parse(e_path)\n",
        "    root = tree.getroot()\n",
        "    d_map = {}\n",
        "    for event in root.findall('.//Event'):\n",
        "        ko = event.find('KickOff')\n",
        "        if ko is not None:\n",
        "            period = ko.get('GameSection')\n",
        "            d_map[period] = {'Left': ko.get('TeamLeft'), 'Right': ko.get('TeamRight')}\n",
        "    return d_map\n",
        "\n",
        "def parse_dfl_positions_to_wide(p_path):\n",
        "    tree = ET.parse(p_path)\n",
        "    root = tree.getroot()\n",
        "    data_dict = defaultdict(dict)\n",
        "    all_pids = set()\n",
        "    for frameset in root.findall('.//FrameSet'):\n",
        "        pID, period = frameset.get('PersonId'), frameset.get('GameSection')\n",
        "        all_pids.add(pID)\n",
        "        for frame in frameset.findall('Frame'):\n",
        "            n = int(frame.get('N'))\n",
        "            data_dict[n][pID] = [float(frame.get('X')), float(frame.get('Y')), float(frame.get('S'))]\n",
        "            data_dict[n]['period'] = period\n",
        "    sorted_frames = sorted(data_dict.keys())\n",
        "    sorted_pIDs = sorted(list(all_pids))\n",
        "    final_data = []\n",
        "    for n in sorted_frames:\n",
        "        row = {'frame_idx': n, 'period': data_dict[n].get('period')}\n",
        "        for pID in sorted_pIDs:\n",
        "            vals = data_dict[n].get(pID, [np.nan, np.nan, np.nan])\n",
        "            name = 'Ball' if '0000XT' in pID else pID\n",
        "            row[f'{name}_x'], row[f'{name}_y'], row[f'{name}_s'] = vals\n",
        "        final_data.append(row)\n",
        "    return pd.DataFrame(final_data).ffill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6Dnzw2x8kND"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 3\n",
        "SET_MANUAL_FLIP = 1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"00000Q\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4k9V1ukr0rp"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 6\n",
        "SET_MANUAL_FLIP = -1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"00000P\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFGDSPV2vSwn"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 5\n",
        "SET_MANUAL_FLIP = 1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"00000H\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHS4m6US3ccv"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 4\n",
        "SET_MANUAL_FLIP = -1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"000005\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-qeAbgU5Kwr"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 2\n",
        "SET_MANUAL_FLIP = 1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"000011\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFaosvvG61Tz"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 1\n",
        "SET_MANUAL_FLIP = 1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"00000B\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"-> 成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka-O1jtv9MIZ"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. 1試合ずつ検証・実行メインループ\n",
        "# ==========================================\n",
        "raw_data_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data\"\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "builder = GNNDataBuilder()\n",
        "\n",
        "# --- 【確定設定】Match 4 救済設定 ---\n",
        "TARGET_MATCH_IDX = 0\n",
        "SET_MANUAL_FLIP = 1.0 # ボール推進率を改善するために反転\n",
        "SET_LEFT_TEAM = \"00000G\"\n",
        "\n",
        "info_files = sorted([f for f in os.listdir(raw_data_path) if \"matchinformation\" in f])\n",
        "i_f = info_files[TARGET_MATCH_IDX]\n",
        "match_id_str = i_f.split('_')[-1].replace('.xml', '')\n",
        "\n",
        "print(f\"\\n===== 【実行】 試合 {TARGET_MATCH_IDX + 1}: {match_id_str} =====\")\n",
        "\n",
        "i_path = os.path.join(raw_data_path, i_f)\n",
        "p_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"positions_raw\" in f)\n",
        "e_path = next(os.path.join(raw_data_path, f) for f in os.listdir(raw_data_path) if match_id_str in f and \"events_raw\" in f)\n",
        "\n",
        "try:\n",
        "    # 1. データの読み込み\n",
        "    sheets = dfl_io.read_teamsheets_from_mat_info_xml(i_path)\n",
        "    df_pos = parse_dfl_positions_to_wide(p_path)\n",
        "    events, _, _ = dfl_io.read_event_data_xml(e_path, i_path)\n",
        "\n",
        "    all_events_list = []\n",
        "    for half in events:\n",
        "        for team_label in events[half]:\n",
        "            df_ev = events[half][team_label].events.copy()\n",
        "            df_ev['tID'] = str(sheets[team_label].teamsheet['tID'].iloc[0]).strip()\n",
        "            df_ev['period'] = half\n",
        "            if 'type' in df_ev.columns: df_ev = df_ev.rename(columns={'type': 'eID'})\n",
        "            all_events_list.append(df_ev)\n",
        "    df_event_all = pd.concat(all_events_list)\n",
        "\n",
        "    # 2. 変換実行\n",
        "    team_map = {'Home': list(sheets['Home'].teamsheet['pID']), 'Away': list(sheets['Away'].teamsheet['pID'])}\n",
        "\n",
        "    match_sequences = builder.extract_sequences(\n",
        "        df_pos=df_pos,\n",
        "        df_event=df_event_all,\n",
        "        match_id_idx=TARGET_MATCH_IDX + 1,\n",
        "        manual_flip=SET_MANUAL_FLIP,\n",
        "        left_team_id=SET_LEFT_TEAM\n",
        "    )\n",
        "\n",
        "    pyg_data = builder.to_pyg_data(match_sequences, team_map)\n",
        "\n",
        "    # 3. 保存\n",
        "    if pyg_data:\n",
        "        save_path = os.path.join(save_dir, f\"match_{TARGET_MATCH_IDX + 1}.pt\")\n",
        "        torch.save(pyg_data, save_path)\n",
        "        print(f\"->  成功: {len(pyg_data)} シーンを保存しました。\")\n",
        "    else:\n",
        "        print(\"->  成功シーンが0件でした。\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"->  エラー: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulv3y1QC6zhD"
      },
      "source": [
        "クロスバリデーションのために、そのまま保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuyT715utreo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# ==========================================\n",
        "# セクション2: データのロード（match_idを明示的に付与）\n",
        "# ==========================================\n",
        "save_dir = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/matches_v17\"\n",
        "final_output_path = \"/content/drive/MyDrive/GNN_Football_Analysis/Processed_Data/gnn_data_v18_final.pt\"\n",
        "\n",
        "match_files = sorted([os.path.join(save_dir, f) for f in os.listdir(save_dir) if f.startswith('match_') and f.endswith('.pt')])\n",
        "all_data = []\n",
        "\n",
        "print(f\"{len(match_files)} 試合分の統合開始...\")\n",
        "\n",
        "for i, f in enumerate(match_files):\n",
        "    # ファイル名に関わらず、1から始まる連番を試合IDとして確定させる\n",
        "    current_match_id = i + 1\n",
        "\n",
        "    m_data = torch.load(f, weights_only=False)\n",
        "\n",
        "    # 【ここが重要！】\n",
        "    # 各データオブジェクトに match_id 属性を追加する\n",
        "    for d in m_data:\n",
        "        d.match_id = torch.tensor([current_match_id])\n",
        "\n",
        "    all_data.extend(m_data)\n",
        "    print(f\" -> {os.path.basename(f)}: {len(m_data)} frames loaded. (Marked as Match {current_match_id})\")\n",
        "\n",
        "# ==========================================\n",
        "# セクション3: 保存\n",
        "# ==========================================\n",
        "print(f\"\\n--- 最終データ構成（CV用・ID刻印済み） ---\")\n",
        "print(f\"総フレーム数: {len(all_data)}\")\n",
        "\n",
        "all_lbls = Counter([int(d.y.item()) for d in all_data])\n",
        "print(f\"全データ内訳: 成功 {all_lbls[1]} 枚 / 失敗 {all_lbls[0]} 枚\")\n",
        "\n",
        "# 試合ごとの内訳も確認（デバッグ用）\n",
        "match_counts = Counter([int(d.match_id.item()) for d in all_data])\n",
        "print(f\"試合別フレーム数: {dict(sorted(match_counts.items()))}\")\n",
        "\n",
        "save_obj = {\n",
        "    'all_data': all_data,\n",
        "    'description': 'v16 integrated data with explicit match_id'\n",
        "}\n",
        "\n",
        "torch.save(save_obj, final_output_path)\n",
        "print(f\"\\n 保存完了: {final_output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDPxb21MstfS2kFSstbazM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}