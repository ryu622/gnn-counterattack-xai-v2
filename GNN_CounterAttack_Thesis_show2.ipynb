{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDrnYuJLdMz5JrUhPkGlOO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryu622/gnn-counterattack-xai-v2/blob/fix%2Ffile-clean/GNN_CounterAttack_Thesis_show2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdMoTADGeH1c"
      },
      "outputs": [],
      "source": [
        "# --- 1. 環境設定と依存関係のインストール ---\n",
        "# 必要なライブラリをすべてインストール\n",
        "!pip install torch-scatter torch-sparse torch-geometric sklearn tqdm networkx matplotlib\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Google Driveをマウント（ファイルアクセスに必須）\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from torch_geometric.utils import dense_to_sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.calibration import calibration_curve\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import logging\n",
        "import copy\n",
        "import json\n",
        "\n",
        "# ロガー設定\n",
        "logger = logging.getLogger(__name__)\n",
        "if not logger.handlers:\n",
        "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
        "    logger.addHandler(stdout_handler)\n",
        "\n",
        "print(\" STEP 1 完了: 環境設定と依存関係のインポートが完了しました。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. データロード、特徴量定義、PyGデータセット変換 ---\n",
        "\n",
        "# --- データロード ---\n",
        "# --- ファイルパス必要に応じて修正 ---\n",
        "file_path = '/content/drive/MyDrive/GNN_Football_Analysis/Raw_Data/women.pkl'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'rb') as handle:\n",
        "        og_data = pickle.load(handle)\n",
        "    print(f\"データロード完了: ファイルパス {file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"重大なエラー: ファイルパス '{file_path}' が見つかりません。パスを修正するか、ファイルをGoogle Driveにアップロードしてください。\")\n",
        "    sys.exit()\n",
        "\n",
        "# --- 特徴量定義のためのウィジェット代替 ---\n",
        "class Checkbox:\n",
        "    def __init__(self, value, description): self.value = value\n",
        "class MockDropdown:\n",
        "    def __init__(self, value): self.value = value\n",
        "class MockVBox:\n",
        "    def __init__(self, children): self.children = children\n",
        "\n",
        "adj_matrix = MockDropdown('normal')\n",
        "edge_f_box = MockVBox([Checkbox(value=True, description='Player Distance')] * 6)\n",
        "node_f_box = MockVBox([Checkbox(value=True, description='x coordinate')] * 12)\n",
        "\n",
        "# --- 特徴量フィルタリング (正しい特徴量名で定義) ---\n",
        "def filter_features(data, gender=None):\n",
        "    CORRECT_NODE_FEATURES = [\n",
        "        \"X Coordinate\", \"Y Coordinate\", \"vX\", \"vY\", \"Speed\", \"Velocity Angle\",\n",
        "        \"Distance to Goal\", \"Angle with Goal\", \"Distance to Ball\", \"Angle with Ball\",\n",
        "        \"Time in Possession\", \"Is Ball Carrier\"\n",
        "    ]\n",
        "    edge_feature_idxs = [idx for idx, x in enumerate(edge_f_box.children) if x.value]\n",
        "    node_feature_idxs = [idx for idx, x in enumerate(node_f_box.children) if x.value]\n",
        "    global node_features\n",
        "    node_features = [CORRECT_NODE_FEATURES[i] for i in node_feature_idxs]\n",
        "    mat_type = adj_matrix.value\n",
        "    data[mat_type]['e'] = [x[:, edge_feature_idxs] for x in data[mat_type]['e']]\n",
        "    data[mat_type]['x'] = [x[:, node_feature_idxs] for x in data[mat_type]['x']]\n",
        "    return data\n",
        "\n",
        "data = filter_features(og_data.copy())\n",
        "\n",
        "# --- PyGデータセットクラスと変換 ---\n",
        "class PyG_CounterDataset(Dataset):\n",
        "    def __init__(self, data, matrix_type):\n",
        "        self.raw_data = data; self.matrix_type = matrix_type\n",
        "        self._data_list = self.process_data()\n",
        "        super().__init__(None, None, None)\n",
        "    def process_data(self):\n",
        "        data_mat = self.raw_data[self.matrix_type]; data_list = []\n",
        "        for x_np, a_np, e_np, y_np in tqdm(zip(data_mat['x'], data_mat['a'], data_mat['e'], self.raw_data['binary']), total=len(data_mat['x']), desc=\"Converting to PyG Data\"):\n",
        "            try:\n",
        "                if x_np.shape[0] == 0: continue\n",
        "                if hasattr(a_np, 'todense'): a_np = a_np.todense()\n",
        "                x = torch.tensor(x_np, dtype=torch.float); a = torch.tensor(a_np, dtype=torch.float)\n",
        "                y = torch.tensor(y_np, dtype=torch.float).view(-1, 1)\n",
        "                edge_index, _ = dense_to_sparse(a)\n",
        "                if edge_index.numel() == 0: continue\n",
        "                data_list.append(Data(x=x, edge_index=edge_index, y=y))\n",
        "            except Exception: continue\n",
        "        return data_list\n",
        "    def len(self): return len(self._data_list)\n",
        "    def get(self, idx): return self._data_list[idx]\n",
        "\n",
        "dataset_pyg = PyG_CounterDataset(data=data, matrix_type='normal')\n",
        "print(f\"STEP 2 完了: PyTorch Geometricデータセットの変換完了。全サンプル数: {len(dataset_pyg)}\")"
      ],
      "metadata": {
        "id": "QzDPV8JQeOm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#結果の保存先の設定\n",
        "\n",
        "# 設定（実行時に書き換える）\n",
        "exp_tag = \"1217_v1\"  # 実験ごとに \"1217_v2\" などに変える(日付→バージョン)\n",
        "\n",
        "# 保存先のパス（Resultsフォルダの下にタグ名でフォルダを作る）\n",
        "save_dir = f'/content/drive/MyDrive/GNN_Football_Analysis/Results/{exp_tag}/'\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "UKTGDqF3GuJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. GATモデル、ハイパーパラメータ、関数の定義 ---\n",
        "\n",
        "# --- ハイパーパラメータ ---\n",
        "CHANNELS = 32; LAYERS = 3; ATTN_HEADS = 4; N_OUT = 1; LEARNING_RATE = 1e-3; EPOCHS = 50; BATCH_SIZE = 32\n",
        "\n",
        "# --- GATモデルクラスの定義 (アテンション抽出機能付き) ---\n",
        "class PyG_GNN_Attn(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, num_layers, num_heads, out_channels):\n",
        "        super(PyG_GNN_Attn, self).__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads, dropout=0.5, concat=True)\n",
        "        self.convs = nn.ModuleList([GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, dropout=0.5, concat=True) for _ in range(num_layers - 1)])\n",
        "        self.conv_out = GATConv(hidden_channels * num_heads, hidden_channels, heads=1, dropout=0.5, concat=False)\n",
        "        self.dense1 = nn.Linear(hidden_channels, hidden_channels); self.dense_out = nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, data, return_attn=False):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        attn_weights = None\n",
        "\n",
        "        if return_attn: x, (edge_index, attn_weights) = self.conv1(x, edge_index, return_attention_weights=True)\n",
        "        else: x = self.conv1(x, edge_index)\n",
        "\n",
        "        x = F.elu(x);\n",
        "        for conv in self.convs: x = F.elu(conv(x, edge_index))\n",
        "        x = F.elu(self.conv_out(x, edge_index))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.relu(self.dense1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        output = torch.sigmoid(self.dense_out(x))\n",
        "\n",
        "        if return_attn: return output, edge_index, attn_weights.squeeze()\n",
        "        return output\n",
        "\n",
        "# --- 訓練/評価関数の定義 ---\n",
        "def train_pyg(model, loader, optimizer, criterion):\n",
        "    model.train(); total_loss = 0; device = next(model.parameters()).device\n",
        "    for data in loader:\n",
        "        data = data.to(device); optimizer.zero_grad(); out = model(data)\n",
        "        loss = criterion(out, data.y); loss.backward(); optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "def evaluate_pyg(model, loader):\n",
        "    model.eval(); preds = []; labels = []; device = next(model.parameters()).device\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device); out = model(data)\n",
        "            preds.append(out.cpu().numpy().flatten()); labels.append(data.y.cpu().numpy().flatten())\n",
        "    preds = np.concatenate(preds); labels = np.concatenate(labels)\n",
        "    if len(np.unique(labels)) > 1: auc = roc_auc_score(labels, preds)\n",
        "    else: auc = 0.0\n",
        "    return auc, preds\n",
        "\n",
        "print(\"STEP 3 完了: モデルクラスと訓練/評価関数の定義が完了しました。\")"
      ],
      "metadata": {
        "id": "6lyzOMh-eoZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. DataLoaderの準備とモデルの訓練 ---\n",
        "\n",
        "# データセット分割\n",
        "final_data_list = dataset_pyg._data_list; indices = np.arange(len(final_data_list))\n",
        "idx_tr, idx_te = train_test_split(indices, test_size=0.3, random_state=42) # 30%をテストに使用\n",
        "dataset_tr_pyg = [final_data_list[i] for i in idx_tr]; dataset_te_pyg = [final_data_list[i] for i in idx_te]\n",
        "\n",
        "loader_tr_pyg = PyGDataLoader(dataset_tr_pyg, batch_size=BATCH_SIZE, shuffle=True)\n",
        "loader_te_pyg_clean = PyGDataLoader(dataset_te_pyg, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# モデルのインスタンス化\n",
        "model_attn = PyG_GNN_Attn(in_channels=dataset_pyg.num_node_features, hidden_channels=CHANNELS, num_layers=LAYERS, num_heads=ATTN_HEADS, out_channels=N_OUT)\n",
        "optimizer_pyg = torch.optim.Adam(model_attn.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# 訓練の実行\n",
        "print(\"\\n PyTorch GATモデルの訓練を開始します...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    loss = train_pyg(model_attn, loader_tr_pyg, optimizer_pyg, criterion)\n",
        "    if epoch % 10 == 0: print(f\"--- Epoch {epoch}/{EPOCHS} --- Loss: {loss:.4f}\")\n",
        "    print(f\"--- Epoch {epoch}/{EPOCHS} --- Training Loss: {loss:.4f}\")\n",
        "print(\"STEP 4 完了: 訓練が完了しました。\")"
      ],
      "metadata": {
        "id": "5uItH98DeqcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. 最終評価とPFIの計算 ---\n",
        "\n",
        "# 評価の実行\n",
        "auc_te, preds_te = evaluate_pyg(model_attn, loader_te_pyg_clean)\n",
        "labels_te = np.concatenate([data.y.numpy().flatten() for data in dataset_te_pyg])\n",
        "\n",
        "print(f\"\\n--- 最終テスト結果 --- AUC: {auc_te:.4f}\")\n",
        "\n",
        "# PFIの関数定義\n",
        "def calculate_permutation_importance(model, loader, features_list, n_repeats=3):\n",
        "    \"\"\"テストデータセット上で、各特徴量のパーミュテーション重要度 (AUCの低下) を計算する\"\"\"\n",
        "    auc, _ = evaluate_pyg(model, loader)\n",
        "    baseline_auc = auc; importance = {}\n",
        "\n",
        "    for idx, feature_name in enumerate(features_list):\n",
        "        auc_decreases = []\n",
        "        for _ in range(n_repeats):\n",
        "            permuted_data_list = [];\n",
        "            for batch_data in loader:\n",
        "                x_permuted = batch_data.x.clone()\n",
        "                perm_indices = torch.randperm(x_permuted.size(0))\n",
        "                x_permuted[:, idx] = x_permuted[perm_indices, idx]\n",
        "                permuted_batch = batch_data.clone(); permuted_batch.x = x_permuted\n",
        "                permuted_data_list.append(permuted_batch)\n",
        "\n",
        "            permuted_loader = PyGDataLoader(permuted_data_list, batch_size=loader.batch_size, shuffle=False)\n",
        "            permuted_auc, _ = evaluate_pyg(model, permuted_loader)\n",
        "            auc_decreases.append(baseline_auc - permuted_auc)\n",
        "\n",
        "        importance[feature_name] = np.mean(auc_decreases)\n",
        "    return importance\n",
        "\n",
        "# PFIの実行 (計算時間を考慮し、ここではn_repeats=3で実行)\n",
        "print(\"\\nPFI (パーミュテーション特徴量重要度) の計算を開始します...\")\n",
        "importance_results = calculate_permutation_importance(model_attn, loader_te_pyg_clean, node_features, n_repeats=3)\n",
        "\n",
        "# PFI結果の可視化\n",
        "sorted_importance = sorted(importance_results.items(), key=lambda item: item[1], reverse=True)\n",
        "print(\"\\n--- 特徴量重要度 (AUC低下量) ---\")\n",
        "for feature, decrease in sorted_importance:\n",
        "    print(f\"[{feature: <20}] : {decrease:.5f}\")\n",
        "\n",
        "features = [item[0] for item in sorted_importance]; decreases = [item[1] for item in sorted_importance]\n",
        "plt.figure(figsize=(10, 6)); plt.barh(features, decreases, color='darkorange')\n",
        "plt.xlabel('AUC Decrease after Permutation (PFI)'); plt.title('Permutation Feature Importance (PyTorch GAT)')\n",
        "plt.gca().invert_yaxis(); plt.grid(axis='x', linestyle='--')\n",
        "plt.tight_layout()\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'pfi.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "plt.show()\n",
        "print(\"STEP 5 完了: PFIの計算と可視化が完了しました。\")"
      ],
      "metadata": {
        "id": "ooOSn-xQesKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. キャリブレーション（較正）曲線の描画 ---\n",
        "\n",
        "prob_true, prob_pred = calibration_curve(y_true=labels_te, y_prob=preds_te, n_bins=10, strategy='uniform')\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.plot(prob_pred, prob_true, marker='o', label='GAT Model')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
        "\n",
        "plt.xlabel(\"Average Predicted Probability (Confidence)\"); plt.ylabel(\"Fraction of Positives (Accuracy)\")\n",
        "plt.title(\"Model Calibration Curve on Test Set\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'Calibration.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"STEP 6 完了: キャリブレーション曲線の描画が完了しました。\")"
      ],
      "metadata": {
        "id": "XP0OA5D9euBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. アテンション係数の可視化 ---\n",
        "\n",
        "# 1. 成功予測フレームの特定\n",
        "model_attn.eval(); max_pred = -1.0; best_index = 0\n",
        "device = next(model_attn.parameters()).device\n",
        "with torch.no_grad():\n",
        "    for idx, data_frame in enumerate(dataset_te_pyg):\n",
        "        data_frame = data_frame.to(device)\n",
        "        prediction_prob = model_attn(data_frame).item()\n",
        "        if prediction_prob > max_pred: max_pred = prediction_prob; best_index = idx\n",
        "\n",
        "# 2. アテンションの抽出\n",
        "single_frame = dataset_te_pyg[best_index]; single_data = single_frame.to(device)\n",
        "with torch.no_grad():\n",
        "    prediction, edge_index_attn, weights_attn = model_attn(single_data, return_attn=True)\n",
        "\n",
        "# 3. NetworkXグラフの構築\n",
        "x_coords = single_data.x[:, 0].cpu().numpy(); y_coords = single_data.x[:, 1].cpu().numpy()\n",
        "edge_list = edge_index_attn.cpu().numpy().T; attention_weights = weights_attn.cpu().numpy()\n",
        "G = nx.Graph(); num_nodes = len(x_coords); G.add_nodes_from(range(num_nodes)); pos = {i: (x_coords[i], y_coords[i]) for i in range(num_nodes)}\n",
        "min_w = attention_weights.min(); max_w = attention_weights.max()\n",
        "normalized_weights_np = 10 * (attention_weights - min_w) / (max_w - min_w + 1e-6) + 1\n",
        "\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "    try: weight_val = float(normalized_weights_np[i].flatten()[0])\n",
        "    except Exception: weight_val = float(normalized_weights_np[i])\n",
        "    G.add_edge(u, v, weight=weight_val)\n",
        "\n",
        "# 4. 可視化の実行\n",
        "plt.figure(figsize=(12, 8)); plt.title(f\"GAT Local Attention Visualization (Prediction: {prediction.item():.2f})\")\n",
        "num_players = 22; num_players_per_team = 11\n",
        "node_colors = ['red'] * num_players_per_team + ['blue'] * num_players_per_team + ['yellow']\n",
        "node_sizes = [300] * num_players + [500]\n",
        "edge_widths = [G[u][v]['weight'] for u, v in G.edges()]\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.7, edge_color='black')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"STEP 7 完了: すべての工程が完了しました。\")"
      ],
      "metadata": {
        "id": "i_fHiryHev0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. 最も高い予測確率を持つフレームの特定 ---\n",
        "model_attn.eval()\n",
        "max_pred = -1.0\n",
        "best_index = -1\n",
        "device = next(model_attn.parameters()).device\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, data_frame in enumerate(dataset_te_pyg):\n",
        "        # モデルと同じデバイスに移動\n",
        "        data_frame = data_frame.to(device)\n",
        "\n",
        "        # 予測確率の取得\n",
        "        prediction_prob = model_attn(data_frame).item()\n",
        "\n",
        "        if prediction_prob > max_pred:\n",
        "            max_pred = prediction_prob\n",
        "            best_index = idx\n",
        "\n",
        "print(f\"最も高い予測確率 {max_pred:.4f} を持つフレームのインデックス: {best_index}\")"
      ],
      "metadata": {
        "id": "NxjfLuYFgPsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 特定フレームのアテンション抽出とグラフの再構築（基本データ生成） ---\n",
        "\n",
        "# 成功フレームのデータ取得\n",
        "single_frame = dataset_te_pyg[best_index]\n",
        "single_data = single_frame.to(next(model_attn.parameters()).device)\n",
        "\n",
        "# アテンション値の抽出\n",
        "with torch.no_grad():\n",
        "    prediction, edge_index_attn, weights_attn = model_attn(single_data, return_attn=True)\n",
        "\n",
        "print(f\"予測確率: {prediction.item():.2f}\")\n",
        "\n",
        "# 3. NetworkXグラフの構築\n",
        "x_coords = single_data.x[:, 0].cpu().numpy()\n",
        "y_coords = single_data.x[:, 1].cpu().numpy()\n",
        "edge_list = edge_index_attn.cpu().numpy().T\n",
        "attention_weights = weights_attn.cpu().numpy()\n",
        "\n",
        "G = nx.Graph()\n",
        "num_nodes = len(x_coords)\n",
        "G.add_nodes_from(range(num_nodes))\n",
        "pos = {i: (x_coords[i], y_coords[i]) for i in range(num_nodes)}\n",
        "\n",
        "# エッジの重み付けと正規化\n",
        "min_w = attention_weights.min()\n",
        "max_w = attention_weights.max()\n",
        "# normalized_weights が以降のフィルタリングに使用されます\n",
        "normalized_weights = 10 * (attention_weights - min_w) / (max_w - min_w + 1e-6) + 1\n",
        "\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "    try:\n",
        "        # NumPyの型をPythonのfloatに変換するロジック\n",
        "        weight_val = float(normalized_weights[i].flatten()[0])\n",
        "    except Exception:\n",
        "        weight_val = float(normalized_weights[i])\n",
        "\n",
        "    G.add_edge(u, v, weight=weight_val)\n",
        "\n",
        "# ノード定義 (グラフ全体で共通)\n",
        "num_players = 22\n",
        "num_players_per_team = 11\n",
        "node_colors = ['red'] * num_players_per_team + ['blue'] * num_players_per_team + ['yellow']\n",
        "node_sizes = [300] * num_players + [500]"
      ],
      "metadata": {
        "id": "gi2O9CBKgSFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. 全体のアテンション可視化 ---\n",
        "#最も高い確率のフレームを可視化\n",
        "\n",
        "edge_widths = [G[u][v]['weight'] for u, v in G.edges()]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Local Attention Visualization (Prediction: {prediction.item():.2f}) - ALL EDGES\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.7, edge_color='black')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_max.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"全体のアテンション可視化が完了しました。\")"
      ],
      "metadata": {
        "id": "IQRcVw2GgUqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. 守備側のみの内部連携 (Blue-Blue) 可視化 ---\n",
        "\n",
        "DEFENSE_START_ID = 11\n",
        "DEFENSE_END_ID = 21\n",
        "\n",
        "defense_edges = []\n",
        "defense_widths = []\n",
        "\n",
        "# Gに格納された重みを参照し、守備-守備のエッジのみをフィルタリング\n",
        "for u, v, data in G.edges(data=True):\n",
        "    is_defense_u = (DEFENSE_START_ID <= u <= DEFENSE_END_ID)\n",
        "    is_defense_v = (DEFENSE_START_ID <= v <= DEFENSE_END_ID)\n",
        "\n",
        "    if is_defense_u and is_defense_v:\n",
        "        defense_edges.append((u, v))\n",
        "        defense_widths.append(data['weight'])\n",
        "\n",
        "# グラフの描画\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Attention: Defense Team Internal Collaboration (Blue-Blue Edges) - Prediction: {prediction.item():.2f}\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=defense_edges, width=defense_widths, alpha=0.9, edge_color='darkblue')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_max_defence.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"守備側のみの連携グラフ描画が完了しました。\")"
      ],
      "metadata": {
        "id": "Ba30VOTggXhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. 攻撃側のみの内部連携 (Red-Red) 可視化 ---\n",
        "\n",
        "ATTACK_START_ID = 0\n",
        "ATTACK_END_ID = 10\n",
        "\n",
        "attack_edges = []\n",
        "attack_widths = []\n",
        "\n",
        "# Gに格納された重みを参照し、攻撃-攻撃のエッジのみをフィルタリング\n",
        "for u, v, data in G.edges(data=True):\n",
        "    is_attack_u = (ATTACK_START_ID <= u <= ATTACK_END_ID)\n",
        "    is_attack_v = (ATTACK_START_ID <= v <= ATTACK_END_ID)\n",
        "\n",
        "    if is_attack_u and is_attack_v:\n",
        "        attack_edges.append((u, v))\n",
        "        attack_widths.append(data['weight'])\n",
        "\n",
        "# グラフの描画\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Attention: Attack Team Internal Collaboration (Red-Red Edges) - Prediction: {prediction.item():.2f}\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=attack_edges, width=attack_widths, alpha=0.9, edge_color='darkred')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_max_attack.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"攻撃側のみの連携グラフ描画が完了しました。\")"
      ],
      "metadata": {
        "id": "lNyFNo4-ganu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#最も低い確率のフレームのアテンション係数の可視化\n",
        "# --- 1. 失敗予測フレーム（確率が最小）を見つける ---\n",
        "model_attn.eval()\n",
        "min_pred = 2.0  # 予測確率の初期値を最大値よりも大きく設定 (シグモイド出力は0から1)\n",
        "best_index_failure = -1\n",
        "device = next(model_attn.parameters()).device\n",
        "\n",
        "with torch.no_grad():\n",
        "    for idx, data_frame in enumerate(dataset_te_pyg):\n",
        "        data_frame = data_frame.to(device)\n",
        "        prediction_prob = model_attn(data_frame).item()\n",
        "\n",
        "        # 予測確率が現在の最小値 (min_pred) よりも低い場合、更新する\n",
        "        if prediction_prob < min_pred:\n",
        "            min_pred = prediction_prob\n",
        "            best_index_failure = idx\n",
        "\n",
        "print(f\"最も低い予測確率 {min_pred:.4f} を持つ失敗フレームのインデックス: {best_index_failure}\")\n",
        "\n",
        "# --- 2. NetworkXグラフの構築 ---\n",
        "\n",
        "# 失敗フレームのデータ取得\n",
        "single_frame = dataset_te_pyg[best_index_failure]\n",
        "single_data = single_frame.to(device)\n",
        "\n",
        "# アテンション値の抽出\n",
        "with torch.no_grad():\n",
        "    prediction, edge_index_attn, weights_attn = model_attn(single_data, return_attn=True)\n",
        "\n",
        "print(f\"失敗予測確率: {prediction.item():.2f}\")\n",
        "\n",
        "# テンソルをCPU上のNumPy配列に変換\n",
        "x_coords = single_data.x[:, 0].cpu().numpy()\n",
        "y_coords = single_data.x[:, 1].cpu().numpy()\n",
        "edge_list = edge_index_attn.cpu().numpy().T\n",
        "attention_weights = weights_attn.cpu().numpy()\n",
        "\n",
        "# NetworkXグラフの構築\n",
        "G = nx.Graph()\n",
        "num_nodes = len(x_coords)\n",
        "G.add_nodes_from(range(num_nodes))\n",
        "pos = {i: (x_coords[i], y_coords[i]) for i in range(num_nodes)}\n",
        "\n",
        "# エッジの重み付けと正規化\n",
        "min_w = attention_weights.min()\n",
        "max_w = attention_weights.max()\n",
        "normalized_weights_np = 10 * (attention_weights - min_w) / (max_w - min_w + 1e-6) + 1\n",
        "\n",
        "# グラフにエッジと重みを追加 (型変換ロジックを維持)\n",
        "for i, (u, v) in enumerate(edge_list):\n",
        "    try:\n",
        "        weight_val = float(np.float64(normalized_weights_np[i]))\n",
        "    except Exception:\n",
        "        weight_val = float(normalized_weights_np[i].flatten()[0])\n",
        "    G.add_edge(u, v, weight=weight_val)\n",
        "\n",
        "# ノード情報 (描画共通)\n",
        "num_players = 22\n",
        "num_players_per_team = 11\n",
        "node_colors = ['red'] * num_players_per_team + ['blue'] * num_players_per_team + ['yellow']\n",
        "node_sizes = [300] * num_players + [500]"
      ],
      "metadata": {
        "id": "2D-cliNMhXOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. 失敗フレーム全体のアテンション可視化 ---\n",
        "\n",
        "edge_widths = [G[u][v]['weight'] for u, v in G.edges()]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Local Attention Visualization (FAILURE Prediction: {prediction.item():.2f}) - ALL EDGES\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.7, edge_color='black')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_min.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"失敗フレーム全体のアテンション可視化が完了しました。\")"
      ],
      "metadata": {
        "id": "lveQ6lwShZde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. 失敗フレーム守備側のみの内部連携 (Blue-Blue) 可視化 ---\n",
        "\n",
        "DEFENSE_START_ID = 11\n",
        "DEFENSE_END_ID = 21\n",
        "\n",
        "defense_edges = []\n",
        "defense_widths = []\n",
        "\n",
        "for u, v, data in G.edges(data=True):\n",
        "    is_defense_u = (DEFENSE_START_ID <= u <= DEFENSE_END_ID)\n",
        "    is_defense_v = (DEFENSE_START_ID <= v <= DEFENSE_END_ID)\n",
        "\n",
        "    if is_defense_u and is_defense_v:\n",
        "        defense_edges.append((u, v))\n",
        "        defense_widths.append(data['weight'])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Attention: Defense Team Internal Collaboration (Blue-Blue Edges) - FAILURE Prediction: {prediction.item():.2f}\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=defense_edges, width=defense_widths, alpha=0.9, edge_color='darkblue')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_min_defence.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"失敗フレーム守備側のみの連携グラフ描画が完了しました。\")"
      ],
      "metadata": {
        "id": "QEYNyimUhgA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. 失敗フレーム攻撃側のみの内部連携 (Red-Red) 可視化 ---\n",
        "\n",
        "ATTACK_START_ID = 0\n",
        "ATTACK_END_ID = 10\n",
        "\n",
        "attack_edges = []\n",
        "attack_widths = []\n",
        "\n",
        "for u, v, data in G.edges(data=True):\n",
        "    is_attack_u = (ATTACK_START_ID <= u <= ATTACK_END_ID)\n",
        "    is_attack_v = (ATTACK_START_ID <= v <= ATTACK_END_ID)\n",
        "\n",
        "    if is_attack_u and is_attack_v:\n",
        "        attack_edges.append((u, v))\n",
        "        attack_widths.append(data['weight'])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(f\"GAT Attention: Attack Team Internal Collaboration (Red-Red Edges) - FAILURE Prediction: {prediction.item():.2f}\")\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=node_colors, label=True)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=attack_edges, width=attack_widths, alpha=0.9, edge_color='darkred')\n",
        "nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.xlabel(\"X Coordinate\")\n",
        "plt.ylabel(\"Y Coordinate\")\n",
        "\n",
        "# --- Google Driveへ保存 ---\n",
        "# save_dir は先ほどのコードで作成したパスを使います\n",
        "fig_path = os.path.join(save_dir, 'AttentionVisualization_attack.png')\n",
        "plt.savefig(fig_path)\n",
        "\n",
        "print(f\"グラフを保存しました: {fig_path}\")\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"失敗フレーム攻撃側のみの連携グラフ描画が完了しました。\")"
      ],
      "metadata": {
        "id": "v8W16sTwhjDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#結果の保存\n",
        "\n",
        "\n",
        "\n",
        "# 1. モデルの保存\n",
        "torch.save(model_attn.state_dict(), os.path.join(save_dir, 'model_weight.pth'))\n",
        "\n",
        "# 2. 学習履歴（Lossなど）の保存\n",
        "# ※実際には学習ループで溜めたhistory変数を使います\n",
        "history = {'train_loss': loss}\n",
        "with open(os.path.join(save_dir, 'history.json'), 'w') as f:\n",
        "    json.dump(history, f)\n",
        "\n",
        "# 3. 設定値の保存\n",
        "config = {\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 32,\n",
        "    'model_type': 'GAT',\n",
        "    'tag': exp_tag\n",
        "}\n",
        "with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "print(f\"保存完了: {save_dir}\")"
      ],
      "metadata": {
        "id": "HrfkdbX9Cjgv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}